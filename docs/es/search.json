[
  {
    "objectID": "step_by_step_guide.html",
    "href": "step_by_step_guide.html",
    "title": "Guía paso a paso para el procesamiento de datos con FOSSILPOL",
    "section": "",
    "text": "El flujo de trabajo FOSSILPOL está estructurado de manera modular, donde todos los pasos se organizan secuencialmente y guiados por un único archivo principal de configuración (Config file) donde todos los criterios y configuraciones se predefinen por el usuario.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nEl flujo de trabajo FOSSILPOL está configurado de manera que los datos de Neotoma Paleoecological Database (“Neotoma” de aquí en adelante) son la fuente principal de datos. Sin embargo, también se pueden utilizar otras fuentes de datos en paralelo utilizando nuestro formato predefinido (Fig. 2). El usuario, por lo tanto, tiene la flexibilidad de obtener datos de Neotoma o de otra fuente de datos siempre que se utilice nuestro archivo de formato predefinido (ver otras fuentes de datos).\nSe requieren tres insumos adicionales para la configuración inicial del flujo de trabajo:\n\nArchivo de configuración (00_Config_file.R) - contiene todos los ajustes seleccionados por el usuario que se aplicarán a lo largo del flujo de trabajo. Estos van desde configuraciones técnicas (por ejemplo, ubicación del almacenamiento de datos) hasta requisitos específicos (por ejemplo, criterios de filtrado) para los registros que se incluirán. Un resumen de dónde se utilizan los criterios de configuración en el flujo de trabajo se resume en (Fig. 2).\nShapefiles geográficos - el flujo de trabajo está configurado internamente para que los datos se procesen por regiones geográficas y los shapefiles se utilizan para asignar la información geográfica relevante a los registros a procesar. Primero, el flujo de trabajo está conceptualizado para un proyecto global, por lo que la estructura general del procesamiento de datos se realiza por continente (es decir, region = “continent”), pero el usuario puede usar cualquier otra delimitación de interés. El flujo de trabajo viene con un shapefile por defecto que delimita aproximadamente los continentes, pero puede ajustarse o reemplazarse según las necesidades del proyecto. En segundo lugar, la armonización taxonómica de los registros se estructura por regiones de armonización proporcionadas por el harmonisation region shapefile. Por defecto, este shapefile es una copia del shapefile continental, pero como las tablas de armonización son específicas por región (ver siguiente ítem de insumo), este shapefile debe ajustarse para representar la delimitación geográfica de las regiones de armonización utilizadas. Finalmente, si el usuario está interesado en otras unidades biogeográficas, climáticas o ecológicas de interés para ser vinculadas a cada registro (por ejemplo, ecorregiones, tipo de bioma, zonas climáticas), entonces se pueden agregar shapefiles (o archivos TIF) adicionales al flujo de trabajo (ver detalles aquí).\nTablas de armonización - en cada proyecto, se debe proporcionar una tabla de armonización por región de armonización (delimitada por el correspondiente shapefile de región de armonización, ver arriba). Una tabla de armonización siempre viene con dos columnas: i) original taxa (taxones originales) con los nombres taxonómicos presentes originalmente en Neotoma y/o en otra fuente de datos en el proyecto, y ii) level_1 (taxones armonizados) con los nombres taxonómicos estandarizados. El flujo de trabajo detectará si el usuario ha proporcionado una tabla de armonización o, de lo contrario, creará una nueva tabla con todos los nombres de taxones brutos detectados para cada región de armonización. Esta última puede servir como plantilla para la armonización en la columna level_1 (ver detalles aquí).\n\n\n\n\n\n\n\nEl flujo de trabajo producirá varios archivos, incluyendo archivos de salida temporales, tablas de stop-check, y salidas finales (compilación de datos, figuras, etc.):\n\nArchivos temporales de salida: el flujo de trabajo está configurado para que los archivos de datos temporales (en proceso) se guarden en varias etapas del flujo de trabajo. Cada archivo contendrá la fecha de creación para una organización más fácil. Cuando se ejecuta varias veces, el flujo de trabajo detectará automáticamente si hay cambios en un archivo seleccionado y solo lo sobrescribirá si se produce un archivo actualizado (esto lo gestiona el paquete {RUtilpol}). Esto también significa que el usuario no tiene que volver a ejecutar todo el flujo de trabajo, sino que puede volver a ejecutar solo partes específicas. Como el tamaño total de los archivos puede ser considerable, el usuario puede especificar si todos los archivos deben almacenarse dentro de la carpeta del proyecto (por defecto) o en otro directorio (especificado usando data_storage_path en el archivo de configuración). Con tal especificación, y después de ejecutar el script 00_Config_file.R, se creará una estructura de carpetas adicional (ver [FLAG]).\nTablas CSV de stop-check: al ejecutar el flujo de trabajo, habrá varias ocasiones en que se pedirá al usuario que revise y, cuando sea necesario, ajuste las tablas CSV producidas para continuar con el flujo de trabajo (es decir, volver a ejecutar el script). Esto se hace para obligar al usuario a comprobar los resultados intermedios antes de continuar. Por ejemplo, en cierto punto, el flujo de trabajo producirá una lista de todos los grupos ecológicos detectados en la compilación de datos obtenida de Neotoma. Luego, el usuario debe editar la tabla CSV mencionada y especificar qué grupos ecológicos deben mantenerse (include = TRUE) y cuáles deben filtrarse (include = FALSE). Ten en cuenta que hay varios stop-checks a lo largo del flujo de trabajo (ver resumen en Fig. 2).\nSalida del flujo de trabajo (Outputs/, ver Sección VII para más información):\n\nuna compilación de datos de polen fósil armonizada taxonómicamente y estandarizada temporalmente, lista para el análisis (formato rds)\ngráficos de curvas de edad-profundidad modeladas para cada registro (formato pdf)\ndiagramas de polen de cada registro (formato pdf)\ntabla de metadatos con el principal contribuyente de datos, información de contacto y publicaciones correspondientes para propósitos de citación de los conjuntos de datos utilizados (PDF).\nreproducibility bundle, un archivo zip que contiene todas las secciones importantes para la reproducibilidad de todo el proyecto.\nfiguras resumen de la distribución espacial y temporal de la compilación de datos, es decir, un mapa y un gráfico de la duración de los registros, respectivamente (PDF).\n\n\n\n\n\n│\n└───Data\n│   │\n│   └───Input\n│   │   │\n│   │   └───Chronology_setting\n│   │   │   │\n│   │   │   └───Bchron_crash\n│   │   │   │\n│   │   │   └───Chron_control_point_types\n│   │   │   │\n│   │   │   └───Percentage_radiocarbon\n│   │   │\n│   │   └───Depositional_environment\n│   │   │   │\n│   │   │   └───Neotoma\n│   │   │   │\n│   │   │   └───Other\n│   │   │\n│   │   └───Eco_group\n│   │   │\n│   │   └───Harmonisation_tables\n│   │   │\n│   │   └───Neotoma_download\n│   │   │\n│   │   └───Potential_duplicates\n│   │   │\n│   │   └───Other\n│   │   │\n│   │   └───Regional_age_limits\n│   │   \n│   └───Personal_database_storage\n│   │\n│   └───Processed\n│       │\n│       └───Chronology\n│       │   │\n│       │   └───Chron_tables_prepared\n│       │   │\n│       │   └───Models_full\n│       │   │\n│       │   └───Predicted_ages\n│       │   │\n│       │   └───Temporary_output\n│       │\n│       └───Data_filtered\n│       │\n│       └───Data_harmonised\n│       │\n│       └───Data_merged\n│       │\n│       └───Data_with_chronologies\n│       │\n│       └───Neotoma_processed\n│       │   │\n│       │   └───Neotoma_chron_control\n│       │   │\n│       │   └───Neotoma_dep_env\n│       │   │\n│       │   └───Neotoma_meta\n│       │\n│       └───Other\n│ \n└───Outputs\n    │\n    └───Data\n    │\n    └───Figures\n    │   │\n    │   └───Chronology\n    │   │\n    │   └───Pollen_diagrams\n    │   \n    └───Tables\n        │\n        └───Meta_and_references\n\n\n\n\n\nAquí nos centramos en los scripts dentro de la carpeta R/01_Data_processing que representan todos los pasos necesarios para el procesamiento de datos (desde la obtención de los datos hasta la compilación final del conjunto de datos), organizados en las siguientes Secciones:\n\nObtención de datos: /01_Neotoma_source/ - obtener y procesar datos de Neotoma\nObtención de datos: /02_Other_source/ - procesar datos de otras fuentes (opcional)\nProcesamiento de datos inicial: /03_Merging_and_geographic_delineation/ - combinar fuentes de datos, filtrar duplicados y asignar valores según la ubicación geográfica\nCronologías: /04_Chronologies/ - preparar tablas de control de cronología, calcular modelos edad-profundidad y predecir edades para los niveles\nArmonización: /05_Harmonisation/ - preparar todas las tablas de armonización y armonizar los taxones de polen (morfotipos)\nFiltrado de datos: /06_Main_filtering/ - filtrar niveles y registros según criterios definidos por el usuario\nSalidas: /07_Outputs/ - guardar la salida final incluyendo la compilación de datos, diagramas de polen, información de metadatos, resumen gráfico y reproducibility bundle\n\n\n\n\n\n\n\nRun_01_01.R - ejecuta todos los scripts dentro de esta carpeta\n01_Download_neotoma.R - descarga los datos de polen desde la base de datos Neotoma\n02_Extract_samples.R - crea una tabla a partir de las listas descargadas de Neotoma y descarga la información de los autores\n03_Filter_dep_env.R - obtiene los datos del ambiente de depósito y filtra registros según las preferencias del usuario\n04_Extract_chron_control_tables.R - obtiene las cronologías, incluyendo la tabla preferida con los puntos de control de cronología\n05_Extract_raw_pollen_data.R - extrae los conteos de polen brutos de Neotoma y filtra por grupos ecológicos seleccionados por el usuario.\n\n\n\nTodos los registros de polen se descargan de Neotoma en base a los criterios geográficos (extensión espacial, Fig. 2 - criterio config 1) y el tipo de dato seleccionado, en este caso: “pollen”. Observa que se puede utilizar una extensión espacial más compleja, como un polígono, con el argumento loc en RFossilpol::proc_neo_get_all_neotoma_datasets() (ver uso de loc en el ejemplo de neotoma2 aquí).\n\n\n\nCada registro se procesa utilizando un ID único de dataset (dataset_id) con la información de metadatos extraída. Los metadatos incluyen información sobre el nombre del registro, información geográfica y los autores y DOI de la publicación conectada al dataset. Los autores y su vínculo con el dataset se guardan en una base de datos de Autor-Dataset creada específicamente para cada proyecto. Esto permite la fácil extracción de autores y DOI para la compilación final producida por el flujo de trabajo.\n\n\n\nLa información de depósito de cada registro ofrece información sobre los ambientes donde se extrajo el registro. Según la pregunta de investigación, puede haber preferencia por ciertos ambientes (por ejemplo, terrestres vs. marinos). Actualmente en Neotoma, los datos sobre ambientes de depósito están organizados en una estructura jerárquica (por ejemplo, “Pond” está anidado en “Natural Lake”, que a su vez está anidado en “Lacustrine”), donde el número máximo de capas anidadas es cinco. En el nivel jerárquico más bajo, actualmente existen más de 50 categorías diferentes de ambientes de depósito (para registros de polen fósil). Según los registros seleccionados, el flujo de trabajo producirá una lista de todos los ambientes de depósito (y su posición jerárquica) presentes en la selección de datos del usuario. Luego se solicita al usuario que defina los ambientes de elección (esto es un punto stop-check, Fig. 2). Observa que excluir ambientes de depósito con una posición jerárquica superior no excluye automáticamente todos los ambientes de depósito anidados en él.\n\n\n\nLos datos de cronología para cada registro están disponibles en una tabla que contiene información sobre los puntos de control de cronología usados para construir un modelo edad-profundidad. Algunos registros pueden tener múltiples tablas de cronología, ya que han sido utilizados para varios proyectos o recalibrados por los responsables de los datos. Estas tablas se enumeran según el orden en que se crearon y subieron. Cada cronología viene con la unidad de edad de la salida del modelo edad-profundidad (por ejemplo, “Radiocarbon years BP”, “Calibrated radiocarbon years BP”) y el rango temporal del registro (edad más joven y más vieja). Las cronologías en “Radiocarbon years BP” suelen ser cronologías más antiguas ya que es práctica común recalibrar el material datado por radiocarbono y producir cronologías expresadas en “Calibrated radiocarbon years BP”. Nota: Las cronologías en “Calibrated radiocarbon years BP” aún vienen con tablas de cronología que contienen las edades de radiocarbono sin calibrar y deben ser calibradas por el usuario si se desea un nuevo modelo edad-profundidad. El flujo de trabajo selecciona automáticamente una tabla por registro según el orden definido por chron_order en el archivo de configuración (Fig. 2 - criterio config 2). Nota: si hay varias tablas con el mismo tipo de unidad de edad (por ejemplo, Calibrated radiocarbon years BP), el flujo de trabajo optará por la tabla más reciente. El usuario puede especificar su preferencia para ciertos tipos de unidad de edad en el archivo de configuración. Además, solo se utilizarán los registros que tengan al menos un número mínimo de puntos de control (definido por min_n_of_control_points en el archivo de configuración, Fig. 2 - criterio config 3).\n\n\n\nCada nivel de cada registro incluye información adicional: a) ID único de muestra (sample_id), b) información sobre la profundidad (y edad estimada posteriormente), y c) conteos de polen para cada taxón presente en ese nivel. La información sobre los niveles se divide en dos tablas diferentes (primero con profundidad y edades, y segundo con conteos de polen) vinculadas por sample_id (sample_id).\nEl flujo de trabajo solo mantendrá los registros con un número mínimo de niveles según lo definido en el archivo de configuración (min_n_levels, Fig. 2 - criterio config 4). El número mínimo de niveles por defecto es tres, pero el usuario puede cambiar este ajuste.\nEn el caso de los datos obtenidos de Neotoma, cada taxón de polen tiene información sobre el grupo ecológico (por ejemplo, palmas, manglares, etc.). Según los registros seleccionados, el flujo de trabajo producirá una lista completa de todos los grupos ecológicos tras lo cual se solicita al usuario definir qué grupos ecológicos incluir (un punto stop-check, Fig. 2, ver explicación de la abreviatura en Tabla 1).\n\n\n\n\n\n\n\n\n\nABREVIATURA\nGRUPO ECOLÓGICO\n\n\n\n\nACRI\nAcritarcos\n\n\nANAC\nAnacrónicos\n\n\nALGA\nAlgas (ej. Botryococcus)\n\n\nAQB\nAcuáticos (ej. Sphagnum)\n\n\nAQVP\nPlantas vasculares acuáticas (ej. Isoetes)\n\n\nBIOM\nMediciones biométricas\n\n\nEMBR\nEmbriófitas\n\n\nFUNG\nHongos\n\n\nLABO\nAnálisis de laboratorio\n\n\nMAN\nManglares\n\n\nPALM\nPalmas\n\n\nPLNT\nPlanta\n\n\nSEED\nNo identificado, pero definitivamente polen - rango o clado de espermatófitos\n\n\nSUCC\nSuculentas\n\n\nTRSH\nÁrboles y arbustos\n\n\nUNID\nDesconocido e indeterminable\n\n\nUPBR\nBriófitas de tierras altas\n\n\nUPHE\nHierbas de tierras altas\n\n\nVACR\nCriptógamas vasculares terrestres\n\n\nVASC\nPlantas vasculares\n\n\n\n\n\n\n\n\n\n\n\n\nRun_01_02.R - ejecuta todos los scripts dentro de esta carpeta\n01_Import_other_data.R - obtener otras fuentes de datos y filtrar los registros de manera similar a Neotoma.\n\n\n\nNuestro flujo de trabajo FOSSILPOL permite el uso de otras fuentes de datos en combinación con los datos de Neotoma. Incluir otras fuentes es completamente opcional y puede omitirse según lo indicado por use_other_datasource = TRUE/FALSE en el archivo de configuración.\nSe pueden usar cualquier tipo de datos, siempre y cuando contengan la siguiente información obligatoria: a) metadatos, b) ambiente de depósito, c) cronología, d) nivel (edad-profundidad), y e) conteos de polen. Para preparar los datos para su uso, el usuario debe descargar la plantilla de archivo especialmente preparada para este fin. Cada registro de polen debe guardarse como un archivo separado con un nombre único. Se recomienda, por ejemplo, private_data_(nombre_del_sitio).xlsx. El nombre del sitio en el nombre del archivo es crucial ya que se comparará con todos los demás registros de polen en Neotoma para detectar posibles duplicados en una etapa posterior del flujo de trabajo. Todos los archivos deben almacenarse en /Data/Input/Other/ (o según lo especificado por el argumento dir_files, ver abajo).\n\n\n\nLa obtención de otras fuentes de datos sigue un orden simple de acciones:\n\nLos archivos de datos deben ser preparados por el usuario siguiendo la plantilla, un registro por archivo.\nLos datos se extraen y formatean para ser compatibles con los datos de Neotoma utilizando la función RFossilpol::import_datasets_from_folder(), con los siguientes argumentos:\n\ndir_files - el usuario puede especificar qué carpeta contiene los datos preparados (por defecto = Data/Input/Other/)\nsuffix - argumento para identificar la fuente de los datos. Por defecto se define como \"other\", lo que significa que los conjuntos de datos se pueden identificar fácilmente ya que su nombre será (dataset id)_other\nsource_of_data - marcará la fuente de cada conjunto de datos en la compilación en el resumen de metadatos (ver sección VII). Por defecto se define como \"personal_data\"\ndata_publicity - marcará la publicidad de los datos de cada conjunto en la compilación en el resumen de metadatos (ver sección VII - Outputs). Por defecto se define como \"restricted\"\npollen_percentage - los conteos de polen medidos como proporciones (por ejemplo, escaneados de diagramas de polen) se pueden marcar aquí. Por defecto en FALSE\n\nLos nombres de los contribuyentes de datos se extraen y se añaden a la base de datos Autor-Dataset usada para la atribución de autor-dataset (ver sección VII - Outputs).\nLos datos se tratan de manera similar a los datos de Neotoma, en cuanto al filtrado por ubicación geográfica, número de niveles (Fig. 2 - criterios config 5, 6), y ambientes de depósito (punto stop-check, Fig. 2).\n\n\n\n\n\n\n\n\n\nRun_01_03.R - ejecuta todos los scripts dentro de esta carpeta\n01_Merge_datasets.R - combinar datos de todas las fuentes, filtrar duplicados y asignar valores según la ubicación geográfica\n\n\n\nDespués del procesamiento inicial, los registros de Neotoma y otras fuentes se combinan.\n\n\nExiste la posibilidad de que algunos conjuntos de datos de otras fuentes ya estén en Neotoma. Para evitar duplicados en la compilación final, el flujo de trabajo comparará conjuntos de ambas fuentes e identificará posibles duplicados. Este paso es opcional, pero se recomienda seguirlo. Para ello, el usuario debe especificar detect_duplicates == TRUE en el archivo de configuración (esto es predeterminado, Fig. 2 - criterio config 7). El flujo de trabajo iniciará una subrutina simple que utiliza la función RFossilpol::proc_filter_out_duplicates(). Dado que comparar todos los registros de cada fuente de datos entre sí es relativamente exigente en términos de cálculo, la función dividirá los datos en varios grupos según su ubicación geográfica (aprox. 100 registros por grupo). El usuario puede definir el número de grupos mediante el argumento n_subgroups. A continuación, cada registro de una fuente se compara con todos los registros de la otra fuente, siempre que se encuentren en un radio de 1 grado (se asume que los registros duplicados estarán en una ubicación similar). El usuario puede definir la distancia máxima mediante el argumento max_degree_distance. Finalmente, el flujo de trabajo generará una lista de posibles registros duplicados (un punto de stop-check, Fig. 2). Para cada par de registros, el usuario debe especificar qué registros deben eliminarse escribiendo 1 (eliminar el Neotoma) o 2 (eliminar la otra fuente de datos) en la columna delete de la lista creada (dejar 0 dejará ambos registros).\n\n\n\nSe realizan varios pasos adicionales para crear la compilación completamente combinada antes de pasar al paso de cronología (no requieren acción del usuario):\n\nTodos los nombres de taxones se transforman en un formato más fácil de manejar por ordenador para su manipulación. La función RFossilpol::proc_clean_count_names() primero transforma los caracteres especiales a texto (por ejemplo, + a _plus_) y luego utiliza {janitor} para transformar en el estilo “snake_case”. Además, el usuario puede especificar cambios adicionales mediante el argumento user_name_patterns (ver ejemplo en el script). Durante la limpieza de nombres de taxones, el flujo de trabajo guardará la taxa_reference_table para la trazabilidad a la taxonomía de Neotoma. La taxa_reference_table es un archivo CSV que se guarda en la misma carpeta que las tablas de armonización (Data/Input/Harmonisation_tables/). Más información sobre el proceso de armonización.\nLos niveles individuales (profundidades de muestra) se ordenan por su profundidad para cada registro con RFossilpol::proc_prepare_raw_count_levels(). Esto incluye subrutinas, por ejemplo, mantener solo los niveles presentes en todas las tablas de datos, filtrar niveles sin datos de polen y taxones que no estén presentes en ningún nivel.\nSe asigna información espacial a cada registro según los shapefiles geográficos proporcionados. Específicamente:\n\nInformación de región - el shapefile en Data/Input/Spatial/Regions_shapefile asignará los nombres regionales a cada registro (ver Sección Entrada de datos). El usuario puede (y se recomienda) cambiar la delimitación espacial alterando o reemplazando el shapefile.\nDelimitación política (países) - obtenido de la base de datos GADM, versión 2.8, noviembre 2015.\nRegión de armonización - el shapefile en Data/Input/Spatial/Harmonisation_regions_shapefile asignará la región de armonización (para vincular la tabla de armonización correspondiente; ver Sección Entrada de datos). El shapefile predeterminado en el flujo de trabajo es una copia del shapefile de información regional, pero debe ajustarse para corresponder al área cubierta por las distintas tablas de armonización.\nCurvas de calibración (normal y post-bomba) - dependiendo de la posición geográfica del registro, se debe asignar una curva de calibración distinta, ya que se usan curvas diferentes para los hemisferios norte y sur, y para ambientes terrestres y marinos. Ver más detalles sobre curvas de calibración.\nAdicional - El usuario puede añadir cualquier otra delimitación espacial (por ejemplo, ecozonas). Esto requerirá agregar el shapefile (o archivo TIF) específico en /Data/Input/Spatial/NOMBRE_DE_LA_CARPETA y ajustar el código R manualmente (optional_info_to_assign) para que el shapefile se lea y su información se asigne a cada registro (ver el ejemplo en el script).\n\nEl flujo de trabajo creará una nueva tabla con los límites de edad para cada región representada en los datos, que debe ser editada por el usuario (un punto stop-check, Fig. 2). Por ejemplo, la tabla Regional_age_limits tendrá los siguientes valores:\n\nyoung_age = edad más joven que debe tener el registro\nold_age = edad más antigua que debe tener el registro\nend_of_interest_period = niveles más allá de esta edad serán omitidos\n\n\n\n\n\n\n\n\n\n\n\nRun_01_04.R - ejecuta todos los scripts dentro de esta carpeta\n01_Prepare_chron_control_tables.R - prepara las tablas de cronología para el modelado edad-profundidad\n02_Run_age_depth_models.R - crea modelos edad-profundidad con BChron\n03_Predict_ages.R - estima las edades de los niveles individuales\n04_Save_AD_figures.R - guarda la salida visual de los modelos edad-profundidad en formato pdf\n05_Merge_chron_output.R - enlaza los modelos edad-profundidad a los conjuntos de datos correspondientes\n\n\n\nPara estimar la edad de los niveles individuales en función de su profundidad, se debe construir un modelo edad-profundidad basado en los datos de cronología del registro. Un modelo edad-profundidad proporciona estimaciones de edad para cada nivel y el rango completo de edades del registro.\nEl modelado edad-profundidad puede ser muy computacionalmente intensivo y llevar bastante tiempo. Por ello, el flujo de trabajo procesa automáticamente varios archivos (formato rds):\n\nTablas de control de cronología:\n\n/Data/Processed/Chronology/Chron_tables_prepared/chron_tables_prepared*.rds contiene todas las tablas de control de cronología preparadas para recalibrarse\n\nModelos edad-profundidad:\n\n/Data/Processed/Chronology/Models_full/* contiene un archivo para cada modelo edad-profundidad\n\nEdades predichas:\n\n/Data/Processed/Chronology/Predicted_ages/predicted_ages*.rds contiene las edades predichas usando los modelos edad-profundidad\n\n\nPuede ser no preferible volver a ejecutar todos los modelos edad-profundidad cada vez que se quiera volver a correr el flujo de trabajo. Por eso, el flujo permite guardar los modelos exitosos (Modelos edad-profundidad y Edades predichas) y mantenerlos entre ejecuciones. Esto se puede hacer de varias formas:\n\nrecalib_AD_models en el archivo de configuración puede fijarse en FALSE. Así se omiten completamente los scripts destinados a calcular los modelos edad-profundidad, y este paso se saltará. Esto solo funciona si los modelos ya fueron creados exitosamente al menos una vez (Edades predichas existen).\ncalc_AD_models_denovo en el archivo de configuración puede fijarse en FALSE (es el valor predeterminado). Si está en TRUE, el flujo no usará los archivos de Modelos edad-profundidad y recalibrará todo “de novo”.\npredict_ages_denovo en el archivo de configuración está en FALSE por defecto. Si está en TRUE, el flujo usará todos los archivos de modelos edad-profundidad pero reasignará las edades a cada nivel de todos los registros relacionados (incluso si ya se predijeron exitosamente antes). Esto es útil, por ejemplo, cuando el número de niveles en un registro aumenta desde la última ejecución y esos niveles aún necesitan edades.\n\nIMPORTANTE: Si seleccionas ambos calc_AD_models_denovo y predict_ages_denovo como FALSE en tu primera ejecución de modelado edad-profundidad, el flujo puede pedirte temporalmente cambiarlos a TRUE en la consola (no tienes que modificar el archivo de configuración).\n\n\n\nLos modelos edad-profundidad se construyen usando puntos de control de cronología (normalmente fechas de radiocarbono) con profundidad conocida, edad estimada y su incertidumbre asociada. Cada registro puede y debe tener varios puntos guardados en la tabla de control de cronología. Cada punto de control tiene las siguientes propiedades:\n\nProfundidad\nEdad estimada\nError de la edad estimada\nTipo de punto de control de cronología\nCurva de calibración utilizada (necesaria para convertir edades de radiocarbono a edades de calendario; ¡ojo! las edades de radiocarbono no son edades de calendario verdaderas).\n\nEste script realiza varios pasos para preparar los registros para el modelado edad-profundidad:\n\nCrear y adjuntar las curvas de calibración necesarias\nSeleccionar los tipos preferidos de puntos de control de cronología\nPreparar tablas de cronología (incluido corregir problemas con porcentaje de carbono si es necesario)\n\n\n\nLas curvas de calibración se asignan a cada punto de control según varios criterios. Si un punto de control tiene un tipo marcado para calibrar (ver sección siguiente), la curva se asigna según la posición geográfica del registro. Solo los puntos de control con edades de radiocarbono sin calibrar requieren recalibración. FOSSILPOL incluye un shapefile basado en la figura 7 de Hogg et al (2020) para asignar correctamente IntCal20, SHCal20 y una curva mixta. Se sigue la recomendación: “…el uso de (i) IntCal20 para áreas al norte de la ITCZ en junio-agosto (líneas discontinuas en la Figura 7) que reciben masas de aire del hemisferio norte durante todo el año, (ii) SHCal20 para áreas al sur de la ITCZ en diciembre-febrero (líneas punteadas en la Figura 7) que reciben masas de aire del hemisferio sur durante todo el año, y (iii) una curva mixta para áreas entre las dos posiciones estacionales de la ITCZ mostradas en la Figura 7, que reciben masas de aire del norte en diciembre-febrero y masas de aire del sur en junio-agosto”. FOSSILPOL también incluye una curva mixta construida con el paquete {rcarbon} con una proporción de contribución de la curva de 1:1. Consulte más información sobre el uso de la curva de calibración mixta.\nTodas las curvas de calibración tienen un límite de edad, es decir, solo pueden usarse para ciertas edades. Las curvas de calibración de radiocarbono actualmente no cubren edades mayores a 55 mil años. Para edades más jóvenes, durante el último siglo, existen problemas con el radiocarbono atmosférico y debe usarse un conjunto distinto de curvas (debido a las detonaciones nucleares en los 50-60, que alteraron la señal atmosférica). Si el punto de control tiene una edad de radiocarbono menor a 200 años BP, se usa una curva post-bomba (ver más arriba). Al igual que las curvas normales, la posición geográfica determina qué curva post-bomba asignar.\nLas fechas modernas de radiocarbono se calibran usando una de las curvas post-bomba (nh_zone_1, nh_zone_2, nh_zone_3, sh_zone_1_2, sh_zone_3), siguiendo a Hua et al., 2013 y enlace. El flujo asignará la curva adecuada automáticamente (ver función IntCal::copyCalibrationCurve()). Si detecta fechas modernas, mostrará los registros y aplicará la conversión usando el paquete {IntCal}.\n\n\n\nCada punto de control tiene varias propiedades: ID único, profundidad, edad, error, espesor y tipo de control (ej. radiocarbono, biostratigráfico, laminaciones anuales, tefra). Cada tipo tiene diferentes incertidumbres de edad. Por ejemplo, muchos registros antiguos se basan en técnicas indirectas (biostratigráficas, tefra, etc.) y pueden tener grandes incertidumbres. Neotoma tiene más de 50 tipos distintos de puntos de control, que abarcan geocronología (ej. plomo-210, radiocarbono, uranio), escala temporal relativa (por ejemplo, MIS5e, Heinrich Stadial 1, Late Wisconsin event), estratigráfica (por ejemplo, eventos bioestratigráficos como la introducción de taxones antropogénicos), cultural (por ejemplo, European Settlement Horizon), otros métodos de datación absoluta (por ejemplo, laminaciones anuales, fecha de recolección) y otros métodos de datación (por ejemplo, extrapolación o conjeturas). Solo los puntos de control cronológico en edades radiocarbónicas sin calibrar requieren recalibración con las curvas de calibración, ya que la mayoría, si no todos, los demás puntos de control estarán en edades calendáricas y no se debe implementar ninguna recalibración.\nEl usuario puede elegir qué tipos de control aceptar “tal cual” y cuáles calibrar (un punto stop-check, Fig. 2). El flujo genera automáticamente una lista con todos los puntos de control detectados, incluyendo columnas include y calibrate. En la primera, el usuario indica si se debe incluir el punto; en la segunda, si debe calibrarse.\n\n\n\nLas tablas de control de cronología deben pasar varios ajustes definidos por el usuario:\n\nfiltrar tipos de puntos de control no deseados seleccionados por el usuario (stop-check)\nfiltrar registros que no cumplan el número mínimo de puntos de control (min_n_of_control_points en el archivo de configuración, por defecto = 2, Fig. 2 - criterio config 8)\ncorregir valores ausentes con default_thickness (por defecto = 1, Fig. 2 - criterio config 9) y default_error (por defecto = 100, Fig. 2 - criterio config 10)\nfiltrar puntos de control con errores demasiado grandes (max_age_error en el archivo de configuración; por defecto = 3000 años, Fig. 2 - criterio config 11)\neliminar puntos de control duplicados en términos de edad y/o profundidad\nen varios casos, el punto de control de la parte superior del núcleo es de tipo guess. El usuario puede especificar que el tipo guess solo sea aceptado hasta cierta profundidad usando guess_depth (por defecto es 10 cm, Fig. 2 - criterio config 12)\n\nAdemás, el número y la distribución de estos puntos pueden indicar la incertidumbre temporal de las edades (Giesecke et al. 2014, Flantua et al. 2016). Un registro con pocos puntos en el periodo de interés tendrá mayor incertidumbre.\n\n\n\nExisten tres maneras de reportar fechas post-bomba de radiocarbono: 1) fechas modernas (&lt;0 F14C años); 2) porcentaje de carbono moderno (pMC, normalizado a 100%); y 3) fracción de radiocarbono (F14C, normalizado a 1; Reimer et al. 2004). Actualmente no hay manera directa de saber si las fechas de Neotoma están en pMC o F14C. Si se detectan, el flujo exporta los registros sospechosos y el usuario debe especificar cuáles deben retrotransformarse (stop-check, Fig. 2). Para los seleccionados, se convierten los valores pMC a edades negativas con IntCal::pMC.age(), tras lo cual se usan las curvas post-bomba para calibrar a edades de calendario.\nAunque F14C se recomienda como estándar, en la práctica la mayoría se reporta como fechas normales de radiocarbono o como pMC. El flujo actualmente no gestiona F14C ya que no se han detectado casos. Si se encuentra con otras fuentes, se puede transformar usando el paquete {IntCal}.\n\n\n\n\nLos modelos edad-profundidad individuales se estiman con el paquete {Bchron}, que estima la trayectoria probabilística bayesiana (modelo no paramétrico). Es apto para diversas combinaciones de tipos de puntos de control, outliers y reversals.\nSi hay muchas edades a profundidades cercanas, pueden producirse problemas de inicialización y Bchron podría no converger. En ese caso, el grosor de los puntos duplicados se aumenta automáticamente por 0.01 (ver argumento artificialThickness en Bchron::Bchronology()).\n\n\nComo crear modelos edad-profundidad para muchos registros puede ser intensivo, el flujo usa computación paralela. Detecta automáticamente los núcleos de la máquina (ajustable con number_of_cores en el archivo de configuración, Fig. 2 - criterio config 14). Los modelos se crean en lotes, con el tamaño determinado por el número de núcleos (batch size, Fig. 2 - criterio config 13; por defecto depende de number_of_cores). Si number_of_cores es 1, no usa el modo lote.\nSi el cálculo del lote falla, el flujo omite ese lote y sigue con los demás. El usuario puede ajustar el tiempo de espera con el argumento time_per_record en RFossilpol::chron_recalibrate_ad_models().\nCada lote se intenta tres veces (ajustable con batch_attempts). Si se detiene el modelado, se usan los lotes exitosos previamente guardados. Si algún registro causa que R se congele completamente, su ID se guarda automáticamente en el archivo Crash (/Data/Input/Chronology_setting/Bchron_crash/) y se omite en futuras ejecuciones. Se recomienda revisar ese dataset en detalle.\n\n\n\nEn el archivo de configuración, el número de iteraciones es 50,000 por defecto, descartando las primeras 10,000 (burn-in) y guardando cada iteración subsiguiente con un salto de 40 (thinning) (Fig. 2 - criterios config 15, 16, 17). El usuario puede cambiar esto con iteration_multiplier (Fig. 2 - criterio config 18). Así, se obtienen 1000 ((50k - 10k) / 40) valores posteriores. El número por defecto es robusto pero se puede aumentar (aunque incrementará el tiempo de espera).\nHay que tener en cuenta que modelar cientos de registros con muchas iteraciones es intensivo y puede llevar decenas de horas o días.\n\n\n\n\nCon un modelo exitoso, se estiman las edades de cada nivel. El flujo calculará la edad y la estimación de error (que engloba el 95% de los valores posteriores: límite superior e inferior). Como {Bchron} es probabilístico, es posible obtener posibles edades. Para ello, se extraen varios valores (por defecto = 1000), se calculan cuartiles, usando el cuantil 50 como edad final y los cuantiles 2.5 y 97.5 como límites. Todo se guarda como matriz de incertidumbre de edad (age_uncertainty). Todo el proceso es automático.\n\n\n\nLa representación visual de todos los modelos edad-profundidad se guarda como PDFs en /Outputs/Figures/Chronologies/, divididos por región. Las propiedades se pueden cambiar en el archivo de configuración (image_width, image_height, image_units, image_dpi, text_size, line_size). Se recomienda revisarlas para buscar errores grandes, hiatos o extrapolaciones extremas.\n\n\n\nLas edades predichas se enlazan con todos los registros de las diferentes fuentes (Secciones I-III). Los niveles de cada registro se ordenan por edades predichas y el mismo orden se aplica a las tablas de conteos de polen.\n\n\n\n\n\n\n\n\nRun_01_05.R - ejecuta todos los scripts dentro de esta carpeta\n01_Harmonisation.R - prepara todas las tablas de armonización y armoniza los conteos brutos.\n\n\n\nEl objetivo de la armonización taxonómica es estandarizar todos los nombres a nivel de sitio a los mismos morfotipos de polen (conjunto de morfotipos de polen y esporas usados para todos los registros), y así reducir el efecto de la incertidumbre taxonómica y la complejidad nomenclatural (ver literatura relevante en el Apéndice 1 de Flantua et al. 2023). Para ello, se puede crear una tabla de armonización que agrupa los morfotipos en el mayor nivel taxonómic que es muy probable que la mayoría de los analistas de polen lo identifiquen.\n\n\n\nPrimero, el flujo de trabajo revisa las regiones de armonización presentes en los datos, definidas por el shapefile (ver Entrada de datos y Sección III), y confirma que exista una tabla de armonización por región (un punto stop-check, Fig. 2). Si falta alguna tabla (o se ejecuta por primera vez), el flujo crea automáticamente una tabla por región, con todos los nombres crudos de taxones de todos los registros de esa región. Cabe destacar que, para simplificar, nos referimos aquí a “nombres de taxón”, pero la identificación suele realizarse a nivel de familia o género, y se denominan mejor morfotipos.\nCada tabla de armonización tiene dos columnas:\n\ntaxon_name es el nombre original del taxón (morfotipo) en formato computacional (snake_case)\nlevel 1, que se usa para agrupar varios taxones (morfotipos) en unidades armonizadas, específicas del proyecto.\n\nPara enlazar los nombres con la visualización original de Neotoma, el usuario puede usar la taxa_reference_table (ver proceso de limpieza de nombres).\nEl usuario puede también definir qué taxones deben eliminarse totalmente durante la armonización (marcados como delete), en caso de errores taxonómicos o proxies no deseados (ej. esporas). Se pueden añadir columnas extra (ej. level_2) y especificar qué niveles incluir ajustando el argumento harm_name en la función RFossilpol::harmonise_all_regions().\nCon estas tablas, cada conjunto se armoniza para que todos los taxones que pertenezcan al mismo taxón armonizado (morfotipo) se sumen en cada nivel; esto aplica tanto para datos de conteo como de porcentaje. El proceso incluye una verificación automática de éxito de la armonización, revisando el número total de granos antes y después de armonizar (puede desactivarse cambiando el argumento pollen_grain_test a FALSE en la función RFossilpol::harmonise_all_regions()).\n\n\n\n\n\n\n\n\nRun_01_06.R - ejecuta todos los scripts dentro de esta carpeta\n01_Level_filtering.R - filtra niveles y registros según los criterios definidos por el usuario en el archivo de configuración\n\n\n\nPara obtener una compilación comprensiva de múltiples registros de polen fósil, mejorar la calidad general y responder preguntas de investigación de forma fiable, recomendamos reducir aún más la selección filtrando niveles individuales y/o registros completos. Todos los criterios de filtrado pueden ser ajustados por el usuario en el archivo de configuración:\n\nfilter_by_pollen_sum (Fig. 2 - criterio config 20) - si es TRUE, el flujo utiliza la cantidad de granos de polen contados en cada nivel como indicador de calidad.\nfilter_by_age_limit (Fig. 2 - criterio config 24) - si es TRUE, se filtran registros que no cubran el periodo de interés definido por el usuario.\nfilter_by_extrapolation (Fig. 2 - criterio config 25) - si es TRUE, se filtran niveles según el número de años extrapolados respecto al último punto de control de cronología usado.\nfilter_by_interest_region (Fig. 2 - criterio config 27) - si es TRUE, se filtran niveles mayores a end_of_interest_period.\nfilter_by_number_of_levels (Fig. 2 - criterio config 28) - si es TRUE, se filtran registros según el número de niveles.\n\nAdemás, se pueden activar dos opciones más:\n\nuse_age_quantiles (Fig. 2 - criterio config 30) - si es TRUE, se usa el cuantil 95 de la edad en el filtrado (incertidumbre).\nuse_bookend_level (Fig. 2 - criterio config 31) - si es TRUE, se deja un nivel adicional más allá de la edad más antigua del periodo de interés.\n\n\n\n\n\n\nEl número de granos contados en cada nivel es un índice de calidad. Para una representación fiable de la vegetación, se recomienda contar más de 300 granos (Moore et al., 1991), aunque pueden usarse otros criterios (por ejemplo, 150; ver Djamali & Cilleros, 2020). En regiones árticas puede bastar con c. 100, en sitios mediterráneos puede llegar a 1000 (Birks & Birks, 1980), pero la preferencia del analista es clave. Números bajos suelen deberse a limitaciones de tiempo, pero también a fenómenos de preservación. Dado que el poder inferencial estadístico es proporcional al tamaño de muestra, recomendamos definir un mínimo de granos en cada nivel. Luego, se puede aceptar un registro solo si X% (por defecto 50, Fig. 2 - criterio config 23) de los niveles cumple el número aceptable.\n\n\n\nSegún el enfoque temporal, solo un subconjunto de registros será de interés. Por tanto, registros que no cubran el periodo de interés serán filtrados si filter_by_age_limit == TRUE.\n\n\n\nLa extrapolación de edades a muestras más allá del último punto de control incrementa la incertidumbre. Recomendamos seleccionar una extrapolación máxima (ej. 5000 años) respecto al último punto de control; niveles más viejos serán filtrados si filter_by_extrapolation == TRUE.\n\n\n\nNiveles fuera del periodo de interés (end_of_interest_period) serán filtrados si filter_by_interest_region == TRUE.\n\n\n\nEl número total de niveles es importante para futuros análisis. Registros con pocos niveles aportan poco y pueden ser fuentes de valores atípicos. Se recomienda definir un número mínimo (min_n_levels, Fig. 2 - criterio config 29); se filtrará si filter_by_number_of_levels == TRUE.\n\n\n\n\n\n\n\n\n\nRun_01_07.R - ejecuta todos los scripts dentro de esta carpeta\n01_Pollen_diagrams.R - guarda los diagramas de polen de todos los registros\n02_Save_assembly.R - guarda el ensamblado de datos con las variables seleccionadas\n03_Save_references.R - guarda referencias y metadatos\n\n\n\nLos diagramas de polen para todos los registros se crean usando el paquete {rioja}. Los datos armonizados se transforman automáticamente en proporción relativa para graficar. Los diagramas se guardan en /Outputs/Figures/Pollen_diagrams/, divididos por Región.\nLa función RFossilpol::plot_all_pollen_diagrams() genera automáticamente un PDF de los diagramas, listos para imprimir. El eje Y es, por defecto, la edad de los niveles (puede cambiarse a profundidad con el argumento y_var). El máximo de taxones por página se ajusta con max_taxa (por defecto, 20). Además, la función omite taxones muy raros, definido por min_n_occur.\n\n\n\nUna compilación armonizada y estandarizada, lista para análisis, se produce y guarda en /Outputs/Data/ como tibble (rds). El usuario puede seleccionar qué columnas deben estar presentes en la compilación final estableciendo select_final_variables == TRUE en el archivo de configuración. El flujo pedirá al usuario en la consola de R si incluir cada variable.\n\n\n\nEl flujo guarda todos los metadatos y la información de citación necesarios para crear la compilación de datos. Todos los resultados están en /Outputs/Meta_and_references/. La función RFossilpol::proc_save_references() lo hace automáticamente, pero el usuario puede especificar qué información guardar usando el argumento user_sel_variables. Por defecto incluye:\n\n\"meta_table\" - tabla de metadatos (data_assembly_meta.csv) contiene por defecto (la lista puede alterarse ajustando variables finales por select_final_variables):\n\nlista de todos los registros en la compilación final\nubicación geográfica\nambiente de depósito\nregión continental asignada\nregión de armonización asignada\nnúmero final de niveles\nnúmero de puntos de control de cronología usados en el modelado edad-profundidad\ncurvas de calibración asignadas\nlímites de edad de cada registro por fuente (Neotoma u otra)\nDOI (de Neotoma)\n\n\"author_table\" - tabla de referencias (authors_meta.csv) con información sobre los conjuntos de datos utilizados, el principal contribuyente y su contacto.\n\"affiliation_table\" - si se provee afiliación con datos distintos de Neotoma, la tabla de afiliaciones (affiliation_table) enlaza autores y afiliaciones.\n\"graphical_summary\" - PDF (graphical_summary*.pdf) con tres figuras usando RFossilpol::plot_graphical_summary():\n\nmapa de ubicación geográfica de los registros\ngráfico de bastones con el número de registros por grupo\nlímites de edad de los registros (línea por registro)\n\n\"reproducibility_bundle\" - un zip (reproducibility_bundle.zip) con el archivo de configuración, todas las tablas stop-check, y todos los shapefiles. La idea es aumentar la reproducibilidad; este zip puede compartirse al publicar un proyecto creado con el flujo FOSSILPOL, o durante revisión para obtener feedback detallado antes de la publicación."
  },
  {
    "objectID": "step_by_step_guide.html#resumen",
    "href": "step_by_step_guide.html#resumen",
    "title": "Guía paso a paso para el procesamiento de datos con FOSSILPOL",
    "section": "",
    "text": "El flujo de trabajo FOSSILPOL está estructurado de manera modular, donde todos los pasos se organizan secuencialmente y guiados por un único archivo principal de configuración (Config file) donde todos los criterios y configuraciones se predefinen por el usuario."
  },
  {
    "objectID": "step_by_step_guide.html#entrada-de-datos",
    "href": "step_by_step_guide.html#entrada-de-datos",
    "title": "Guía paso a paso para el procesamiento de datos con FOSSILPOL",
    "section": "",
    "text": "El flujo de trabajo FOSSILPOL está configurado de manera que los datos de Neotoma Paleoecological Database (“Neotoma” de aquí en adelante) son la fuente principal de datos. Sin embargo, también se pueden utilizar otras fuentes de datos en paralelo utilizando nuestro formato predefinido (Fig. 2). El usuario, por lo tanto, tiene la flexibilidad de obtener datos de Neotoma o de otra fuente de datos siempre que se utilice nuestro archivo de formato predefinido (ver otras fuentes de datos).\nSe requieren tres insumos adicionales para la configuración inicial del flujo de trabajo:\n\nArchivo de configuración (00_Config_file.R) - contiene todos los ajustes seleccionados por el usuario que se aplicarán a lo largo del flujo de trabajo. Estos van desde configuraciones técnicas (por ejemplo, ubicación del almacenamiento de datos) hasta requisitos específicos (por ejemplo, criterios de filtrado) para los registros que se incluirán. Un resumen de dónde se utilizan los criterios de configuración en el flujo de trabajo se resume en (Fig. 2).\nShapefiles geográficos - el flujo de trabajo está configurado internamente para que los datos se procesen por regiones geográficas y los shapefiles se utilizan para asignar la información geográfica relevante a los registros a procesar. Primero, el flujo de trabajo está conceptualizado para un proyecto global, por lo que la estructura general del procesamiento de datos se realiza por continente (es decir, region = “continent”), pero el usuario puede usar cualquier otra delimitación de interés. El flujo de trabajo viene con un shapefile por defecto que delimita aproximadamente los continentes, pero puede ajustarse o reemplazarse según las necesidades del proyecto. En segundo lugar, la armonización taxonómica de los registros se estructura por regiones de armonización proporcionadas por el harmonisation region shapefile. Por defecto, este shapefile es una copia del shapefile continental, pero como las tablas de armonización son específicas por región (ver siguiente ítem de insumo), este shapefile debe ajustarse para representar la delimitación geográfica de las regiones de armonización utilizadas. Finalmente, si el usuario está interesado en otras unidades biogeográficas, climáticas o ecológicas de interés para ser vinculadas a cada registro (por ejemplo, ecorregiones, tipo de bioma, zonas climáticas), entonces se pueden agregar shapefiles (o archivos TIF) adicionales al flujo de trabajo (ver detalles aquí).\nTablas de armonización - en cada proyecto, se debe proporcionar una tabla de armonización por región de armonización (delimitada por el correspondiente shapefile de región de armonización, ver arriba). Una tabla de armonización siempre viene con dos columnas: i) original taxa (taxones originales) con los nombres taxonómicos presentes originalmente en Neotoma y/o en otra fuente de datos en el proyecto, y ii) level_1 (taxones armonizados) con los nombres taxonómicos estandarizados. El flujo de trabajo detectará si el usuario ha proporcionado una tabla de armonización o, de lo contrario, creará una nueva tabla con todos los nombres de taxones brutos detectados para cada región de armonización. Esta última puede servir como plantilla para la armonización en la columna level_1 (ver detalles aquí)."
  },
  {
    "objectID": "step_by_step_guide.html#almacenamiento-de-datos",
    "href": "step_by_step_guide.html#almacenamiento-de-datos",
    "title": "Guía paso a paso para el procesamiento de datos con FOSSILPOL",
    "section": "",
    "text": "El flujo de trabajo producirá varios archivos, incluyendo archivos de salida temporales, tablas de stop-check, y salidas finales (compilación de datos, figuras, etc.):\n\nArchivos temporales de salida: el flujo de trabajo está configurado para que los archivos de datos temporales (en proceso) se guarden en varias etapas del flujo de trabajo. Cada archivo contendrá la fecha de creación para una organización más fácil. Cuando se ejecuta varias veces, el flujo de trabajo detectará automáticamente si hay cambios en un archivo seleccionado y solo lo sobrescribirá si se produce un archivo actualizado (esto lo gestiona el paquete {RUtilpol}). Esto también significa que el usuario no tiene que volver a ejecutar todo el flujo de trabajo, sino que puede volver a ejecutar solo partes específicas. Como el tamaño total de los archivos puede ser considerable, el usuario puede especificar si todos los archivos deben almacenarse dentro de la carpeta del proyecto (por defecto) o en otro directorio (especificado usando data_storage_path en el archivo de configuración). Con tal especificación, y después de ejecutar el script 00_Config_file.R, se creará una estructura de carpetas adicional (ver [FLAG]).\nTablas CSV de stop-check: al ejecutar el flujo de trabajo, habrá varias ocasiones en que se pedirá al usuario que revise y, cuando sea necesario, ajuste las tablas CSV producidas para continuar con el flujo de trabajo (es decir, volver a ejecutar el script). Esto se hace para obligar al usuario a comprobar los resultados intermedios antes de continuar. Por ejemplo, en cierto punto, el flujo de trabajo producirá una lista de todos los grupos ecológicos detectados en la compilación de datos obtenida de Neotoma. Luego, el usuario debe editar la tabla CSV mencionada y especificar qué grupos ecológicos deben mantenerse (include = TRUE) y cuáles deben filtrarse (include = FALSE). Ten en cuenta que hay varios stop-checks a lo largo del flujo de trabajo (ver resumen en Fig. 2).\nSalida del flujo de trabajo (Outputs/, ver Sección VII para más información):\n\nuna compilación de datos de polen fósil armonizada taxonómicamente y estandarizada temporalmente, lista para el análisis (formato rds)\ngráficos de curvas de edad-profundidad modeladas para cada registro (formato pdf)\ndiagramas de polen de cada registro (formato pdf)\ntabla de metadatos con el principal contribuyente de datos, información de contacto y publicaciones correspondientes para propósitos de citación de los conjuntos de datos utilizados (PDF).\nreproducibility bundle, un archivo zip que contiene todas las secciones importantes para la reproducibilidad de todo el proyecto.\nfiguras resumen de la distribución espacial y temporal de la compilación de datos, es decir, un mapa y un gráfico de la duración de los registros, respectivamente (PDF).\n\n\n\n\n\n│\n└───Data\n│   │\n│   └───Input\n│   │   │\n│   │   └───Chronology_setting\n│   │   │   │\n│   │   │   └───Bchron_crash\n│   │   │   │\n│   │   │   └───Chron_control_point_types\n│   │   │   │\n│   │   │   └───Percentage_radiocarbon\n│   │   │\n│   │   └───Depositional_environment\n│   │   │   │\n│   │   │   └───Neotoma\n│   │   │   │\n│   │   │   └───Other\n│   │   │\n│   │   └───Eco_group\n│   │   │\n│   │   └───Harmonisation_tables\n│   │   │\n│   │   └───Neotoma_download\n│   │   │\n│   │   └───Potential_duplicates\n│   │   │\n│   │   └───Other\n│   │   │\n│   │   └───Regional_age_limits\n│   │   \n│   └───Personal_database_storage\n│   │\n│   └───Processed\n│       │\n│       └───Chronology\n│       │   │\n│       │   └───Chron_tables_prepared\n│       │   │\n│       │   └───Models_full\n│       │   │\n│       │   └───Predicted_ages\n│       │   │\n│       │   └───Temporary_output\n│       │\n│       └───Data_filtered\n│       │\n│       └───Data_harmonised\n│       │\n│       └───Data_merged\n│       │\n│       └───Data_with_chronologies\n│       │\n│       └───Neotoma_processed\n│       │   │\n│       │   └───Neotoma_chron_control\n│       │   │\n│       │   └───Neotoma_dep_env\n│       │   │\n│       │   └───Neotoma_meta\n│       │\n│       └───Other\n│ \n└───Outputs\n    │\n    └───Data\n    │\n    └───Figures\n    │   │\n    │   └───Chronology\n    │   │\n    │   └───Pollen_diagrams\n    │   \n    └───Tables\n        │\n        └───Meta_and_references"
  },
  {
    "objectID": "step_by_step_guide.html#procesamiento-de-datos",
    "href": "step_by_step_guide.html#procesamiento-de-datos",
    "title": "Guía paso a paso para el procesamiento de datos con FOSSILPOL",
    "section": "",
    "text": "Aquí nos centramos en los scripts dentro de la carpeta R/01_Data_processing que representan todos los pasos necesarios para el procesamiento de datos (desde la obtención de los datos hasta la compilación final del conjunto de datos), organizados en las siguientes Secciones:\n\nObtención de datos: /01_Neotoma_source/ - obtener y procesar datos de Neotoma\nObtención de datos: /02_Other_source/ - procesar datos de otras fuentes (opcional)\nProcesamiento de datos inicial: /03_Merging_and_geographic_delineation/ - combinar fuentes de datos, filtrar duplicados y asignar valores según la ubicación geográfica\nCronologías: /04_Chronologies/ - preparar tablas de control de cronología, calcular modelos edad-profundidad y predecir edades para los niveles\nArmonización: /05_Harmonisation/ - preparar todas las tablas de armonización y armonizar los taxones de polen (morfotipos)\nFiltrado de datos: /06_Main_filtering/ - filtrar niveles y registros según criterios definidos por el usuario\nSalidas: /07_Outputs/ - guardar la salida final incluyendo la compilación de datos, diagramas de polen, información de metadatos, resumen gráfico y reproducibility bundle\n\n\n\n\n\n\n\nRun_01_01.R - ejecuta todos los scripts dentro de esta carpeta\n01_Download_neotoma.R - descarga los datos de polen desde la base de datos Neotoma\n02_Extract_samples.R - crea una tabla a partir de las listas descargadas de Neotoma y descarga la información de los autores\n03_Filter_dep_env.R - obtiene los datos del ambiente de depósito y filtra registros según las preferencias del usuario\n04_Extract_chron_control_tables.R - obtiene las cronologías, incluyendo la tabla preferida con los puntos de control de cronología\n05_Extract_raw_pollen_data.R - extrae los conteos de polen brutos de Neotoma y filtra por grupos ecológicos seleccionados por el usuario.\n\n\n\nTodos los registros de polen se descargan de Neotoma en base a los criterios geográficos (extensión espacial, Fig. 2 - criterio config 1) y el tipo de dato seleccionado, en este caso: “pollen”. Observa que se puede utilizar una extensión espacial más compleja, como un polígono, con el argumento loc en RFossilpol::proc_neo_get_all_neotoma_datasets() (ver uso de loc en el ejemplo de neotoma2 aquí).\n\n\n\nCada registro se procesa utilizando un ID único de dataset (dataset_id) con la información de metadatos extraída. Los metadatos incluyen información sobre el nombre del registro, información geográfica y los autores y DOI de la publicación conectada al dataset. Los autores y su vínculo con el dataset se guardan en una base de datos de Autor-Dataset creada específicamente para cada proyecto. Esto permite la fácil extracción de autores y DOI para la compilación final producida por el flujo de trabajo.\n\n\n\nLa información de depósito de cada registro ofrece información sobre los ambientes donde se extrajo el registro. Según la pregunta de investigación, puede haber preferencia por ciertos ambientes (por ejemplo, terrestres vs. marinos). Actualmente en Neotoma, los datos sobre ambientes de depósito están organizados en una estructura jerárquica (por ejemplo, “Pond” está anidado en “Natural Lake”, que a su vez está anidado en “Lacustrine”), donde el número máximo de capas anidadas es cinco. En el nivel jerárquico más bajo, actualmente existen más de 50 categorías diferentes de ambientes de depósito (para registros de polen fósil). Según los registros seleccionados, el flujo de trabajo producirá una lista de todos los ambientes de depósito (y su posición jerárquica) presentes en la selección de datos del usuario. Luego se solicita al usuario que defina los ambientes de elección (esto es un punto stop-check, Fig. 2). Observa que excluir ambientes de depósito con una posición jerárquica superior no excluye automáticamente todos los ambientes de depósito anidados en él.\n\n\n\nLos datos de cronología para cada registro están disponibles en una tabla que contiene información sobre los puntos de control de cronología usados para construir un modelo edad-profundidad. Algunos registros pueden tener múltiples tablas de cronología, ya que han sido utilizados para varios proyectos o recalibrados por los responsables de los datos. Estas tablas se enumeran según el orden en que se crearon y subieron. Cada cronología viene con la unidad de edad de la salida del modelo edad-profundidad (por ejemplo, “Radiocarbon years BP”, “Calibrated radiocarbon years BP”) y el rango temporal del registro (edad más joven y más vieja). Las cronologías en “Radiocarbon years BP” suelen ser cronologías más antiguas ya que es práctica común recalibrar el material datado por radiocarbono y producir cronologías expresadas en “Calibrated radiocarbon years BP”. Nota: Las cronologías en “Calibrated radiocarbon years BP” aún vienen con tablas de cronología que contienen las edades de radiocarbono sin calibrar y deben ser calibradas por el usuario si se desea un nuevo modelo edad-profundidad. El flujo de trabajo selecciona automáticamente una tabla por registro según el orden definido por chron_order en el archivo de configuración (Fig. 2 - criterio config 2). Nota: si hay varias tablas con el mismo tipo de unidad de edad (por ejemplo, Calibrated radiocarbon years BP), el flujo de trabajo optará por la tabla más reciente. El usuario puede especificar su preferencia para ciertos tipos de unidad de edad en el archivo de configuración. Además, solo se utilizarán los registros que tengan al menos un número mínimo de puntos de control (definido por min_n_of_control_points en el archivo de configuración, Fig. 2 - criterio config 3).\n\n\n\nCada nivel de cada registro incluye información adicional: a) ID único de muestra (sample_id), b) información sobre la profundidad (y edad estimada posteriormente), y c) conteos de polen para cada taxón presente en ese nivel. La información sobre los niveles se divide en dos tablas diferentes (primero con profundidad y edades, y segundo con conteos de polen) vinculadas por sample_id (sample_id).\nEl flujo de trabajo solo mantendrá los registros con un número mínimo de niveles según lo definido en el archivo de configuración (min_n_levels, Fig. 2 - criterio config 4). El número mínimo de niveles por defecto es tres, pero el usuario puede cambiar este ajuste.\nEn el caso de los datos obtenidos de Neotoma, cada taxón de polen tiene información sobre el grupo ecológico (por ejemplo, palmas, manglares, etc.). Según los registros seleccionados, el flujo de trabajo producirá una lista completa de todos los grupos ecológicos tras lo cual se solicita al usuario definir qué grupos ecológicos incluir (un punto stop-check, Fig. 2, ver explicación de la abreviatura en Tabla 1).\n\n\n\n\n\n\n\n\n\nABREVIATURA\nGRUPO ECOLÓGICO\n\n\n\n\nACRI\nAcritarcos\n\n\nANAC\nAnacrónicos\n\n\nALGA\nAlgas (ej. Botryococcus)\n\n\nAQB\nAcuáticos (ej. Sphagnum)\n\n\nAQVP\nPlantas vasculares acuáticas (ej. Isoetes)\n\n\nBIOM\nMediciones biométricas\n\n\nEMBR\nEmbriófitas\n\n\nFUNG\nHongos\n\n\nLABO\nAnálisis de laboratorio\n\n\nMAN\nManglares\n\n\nPALM\nPalmas\n\n\nPLNT\nPlanta\n\n\nSEED\nNo identificado, pero definitivamente polen - rango o clado de espermatófitos\n\n\nSUCC\nSuculentas\n\n\nTRSH\nÁrboles y arbustos\n\n\nUNID\nDesconocido e indeterminable\n\n\nUPBR\nBriófitas de tierras altas\n\n\nUPHE\nHierbas de tierras altas\n\n\nVACR\nCriptógamas vasculares terrestres\n\n\nVASC\nPlantas vasculares\n\n\n\n\n\n\n\n\n\n\n\n\nRun_01_02.R - ejecuta todos los scripts dentro de esta carpeta\n01_Import_other_data.R - obtener otras fuentes de datos y filtrar los registros de manera similar a Neotoma.\n\n\n\nNuestro flujo de trabajo FOSSILPOL permite el uso de otras fuentes de datos en combinación con los datos de Neotoma. Incluir otras fuentes es completamente opcional y puede omitirse según lo indicado por use_other_datasource = TRUE/FALSE en el archivo de configuración.\nSe pueden usar cualquier tipo de datos, siempre y cuando contengan la siguiente información obligatoria: a) metadatos, b) ambiente de depósito, c) cronología, d) nivel (edad-profundidad), y e) conteos de polen. Para preparar los datos para su uso, el usuario debe descargar la plantilla de archivo especialmente preparada para este fin. Cada registro de polen debe guardarse como un archivo separado con un nombre único. Se recomienda, por ejemplo, private_data_(nombre_del_sitio).xlsx. El nombre del sitio en el nombre del archivo es crucial ya que se comparará con todos los demás registros de polen en Neotoma para detectar posibles duplicados en una etapa posterior del flujo de trabajo. Todos los archivos deben almacenarse en /Data/Input/Other/ (o según lo especificado por el argumento dir_files, ver abajo).\n\n\n\nLa obtención de otras fuentes de datos sigue un orden simple de acciones:\n\nLos archivos de datos deben ser preparados por el usuario siguiendo la plantilla, un registro por archivo.\nLos datos se extraen y formatean para ser compatibles con los datos de Neotoma utilizando la función RFossilpol::import_datasets_from_folder(), con los siguientes argumentos:\n\ndir_files - el usuario puede especificar qué carpeta contiene los datos preparados (por defecto = Data/Input/Other/)\nsuffix - argumento para identificar la fuente de los datos. Por defecto se define como \"other\", lo que significa que los conjuntos de datos se pueden identificar fácilmente ya que su nombre será (dataset id)_other\nsource_of_data - marcará la fuente de cada conjunto de datos en la compilación en el resumen de metadatos (ver sección VII). Por defecto se define como \"personal_data\"\ndata_publicity - marcará la publicidad de los datos de cada conjunto en la compilación en el resumen de metadatos (ver sección VII - Outputs). Por defecto se define como \"restricted\"\npollen_percentage - los conteos de polen medidos como proporciones (por ejemplo, escaneados de diagramas de polen) se pueden marcar aquí. Por defecto en FALSE\n\nLos nombres de los contribuyentes de datos se extraen y se añaden a la base de datos Autor-Dataset usada para la atribución de autor-dataset (ver sección VII - Outputs).\nLos datos se tratan de manera similar a los datos de Neotoma, en cuanto al filtrado por ubicación geográfica, número de niveles (Fig. 2 - criterios config 5, 6), y ambientes de depósito (punto stop-check, Fig. 2).\n\n\n\n\n\n\n\n\n\nRun_01_03.R - ejecuta todos los scripts dentro de esta carpeta\n01_Merge_datasets.R - combinar datos de todas las fuentes, filtrar duplicados y asignar valores según la ubicación geográfica\n\n\n\nDespués del procesamiento inicial, los registros de Neotoma y otras fuentes se combinan.\n\n\nExiste la posibilidad de que algunos conjuntos de datos de otras fuentes ya estén en Neotoma. Para evitar duplicados en la compilación final, el flujo de trabajo comparará conjuntos de ambas fuentes e identificará posibles duplicados. Este paso es opcional, pero se recomienda seguirlo. Para ello, el usuario debe especificar detect_duplicates == TRUE en el archivo de configuración (esto es predeterminado, Fig. 2 - criterio config 7). El flujo de trabajo iniciará una subrutina simple que utiliza la función RFossilpol::proc_filter_out_duplicates(). Dado que comparar todos los registros de cada fuente de datos entre sí es relativamente exigente en términos de cálculo, la función dividirá los datos en varios grupos según su ubicación geográfica (aprox. 100 registros por grupo). El usuario puede definir el número de grupos mediante el argumento n_subgroups. A continuación, cada registro de una fuente se compara con todos los registros de la otra fuente, siempre que se encuentren en un radio de 1 grado (se asume que los registros duplicados estarán en una ubicación similar). El usuario puede definir la distancia máxima mediante el argumento max_degree_distance. Finalmente, el flujo de trabajo generará una lista de posibles registros duplicados (un punto de stop-check, Fig. 2). Para cada par de registros, el usuario debe especificar qué registros deben eliminarse escribiendo 1 (eliminar el Neotoma) o 2 (eliminar la otra fuente de datos) en la columna delete de la lista creada (dejar 0 dejará ambos registros).\n\n\n\nSe realizan varios pasos adicionales para crear la compilación completamente combinada antes de pasar al paso de cronología (no requieren acción del usuario):\n\nTodos los nombres de taxones se transforman en un formato más fácil de manejar por ordenador para su manipulación. La función RFossilpol::proc_clean_count_names() primero transforma los caracteres especiales a texto (por ejemplo, + a _plus_) y luego utiliza {janitor} para transformar en el estilo “snake_case”. Además, el usuario puede especificar cambios adicionales mediante el argumento user_name_patterns (ver ejemplo en el script). Durante la limpieza de nombres de taxones, el flujo de trabajo guardará la taxa_reference_table para la trazabilidad a la taxonomía de Neotoma. La taxa_reference_table es un archivo CSV que se guarda en la misma carpeta que las tablas de armonización (Data/Input/Harmonisation_tables/). Más información sobre el proceso de armonización.\nLos niveles individuales (profundidades de muestra) se ordenan por su profundidad para cada registro con RFossilpol::proc_prepare_raw_count_levels(). Esto incluye subrutinas, por ejemplo, mantener solo los niveles presentes en todas las tablas de datos, filtrar niveles sin datos de polen y taxones que no estén presentes en ningún nivel.\nSe asigna información espacial a cada registro según los shapefiles geográficos proporcionados. Específicamente:\n\nInformación de región - el shapefile en Data/Input/Spatial/Regions_shapefile asignará los nombres regionales a cada registro (ver Sección Entrada de datos). El usuario puede (y se recomienda) cambiar la delimitación espacial alterando o reemplazando el shapefile.\nDelimitación política (países) - obtenido de la base de datos GADM, versión 2.8, noviembre 2015.\nRegión de armonización - el shapefile en Data/Input/Spatial/Harmonisation_regions_shapefile asignará la región de armonización (para vincular la tabla de armonización correspondiente; ver Sección Entrada de datos). El shapefile predeterminado en el flujo de trabajo es una copia del shapefile de información regional, pero debe ajustarse para corresponder al área cubierta por las distintas tablas de armonización.\nCurvas de calibración (normal y post-bomba) - dependiendo de la posición geográfica del registro, se debe asignar una curva de calibración distinta, ya que se usan curvas diferentes para los hemisferios norte y sur, y para ambientes terrestres y marinos. Ver más detalles sobre curvas de calibración.\nAdicional - El usuario puede añadir cualquier otra delimitación espacial (por ejemplo, ecozonas). Esto requerirá agregar el shapefile (o archivo TIF) específico en /Data/Input/Spatial/NOMBRE_DE_LA_CARPETA y ajustar el código R manualmente (optional_info_to_assign) para que el shapefile se lea y su información se asigne a cada registro (ver el ejemplo en el script).\n\nEl flujo de trabajo creará una nueva tabla con los límites de edad para cada región representada en los datos, que debe ser editada por el usuario (un punto stop-check, Fig. 2). Por ejemplo, la tabla Regional_age_limits tendrá los siguientes valores:\n\nyoung_age = edad más joven que debe tener el registro\nold_age = edad más antigua que debe tener el registro\nend_of_interest_period = niveles más allá de esta edad serán omitidos\n\n\n\n\n\n\n\n\n\n\n\nRun_01_04.R - ejecuta todos los scripts dentro de esta carpeta\n01_Prepare_chron_control_tables.R - prepara las tablas de cronología para el modelado edad-profundidad\n02_Run_age_depth_models.R - crea modelos edad-profundidad con BChron\n03_Predict_ages.R - estima las edades de los niveles individuales\n04_Save_AD_figures.R - guarda la salida visual de los modelos edad-profundidad en formato pdf\n05_Merge_chron_output.R - enlaza los modelos edad-profundidad a los conjuntos de datos correspondientes\n\n\n\nPara estimar la edad de los niveles individuales en función de su profundidad, se debe construir un modelo edad-profundidad basado en los datos de cronología del registro. Un modelo edad-profundidad proporciona estimaciones de edad para cada nivel y el rango completo de edades del registro.\nEl modelado edad-profundidad puede ser muy computacionalmente intensivo y llevar bastante tiempo. Por ello, el flujo de trabajo procesa automáticamente varios archivos (formato rds):\n\nTablas de control de cronología:\n\n/Data/Processed/Chronology/Chron_tables_prepared/chron_tables_prepared*.rds contiene todas las tablas de control de cronología preparadas para recalibrarse\n\nModelos edad-profundidad:\n\n/Data/Processed/Chronology/Models_full/* contiene un archivo para cada modelo edad-profundidad\n\nEdades predichas:\n\n/Data/Processed/Chronology/Predicted_ages/predicted_ages*.rds contiene las edades predichas usando los modelos edad-profundidad\n\n\nPuede ser no preferible volver a ejecutar todos los modelos edad-profundidad cada vez que se quiera volver a correr el flujo de trabajo. Por eso, el flujo permite guardar los modelos exitosos (Modelos edad-profundidad y Edades predichas) y mantenerlos entre ejecuciones. Esto se puede hacer de varias formas:\n\nrecalib_AD_models en el archivo de configuración puede fijarse en FALSE. Así se omiten completamente los scripts destinados a calcular los modelos edad-profundidad, y este paso se saltará. Esto solo funciona si los modelos ya fueron creados exitosamente al menos una vez (Edades predichas existen).\ncalc_AD_models_denovo en el archivo de configuración puede fijarse en FALSE (es el valor predeterminado). Si está en TRUE, el flujo no usará los archivos de Modelos edad-profundidad y recalibrará todo “de novo”.\npredict_ages_denovo en el archivo de configuración está en FALSE por defecto. Si está en TRUE, el flujo usará todos los archivos de modelos edad-profundidad pero reasignará las edades a cada nivel de todos los registros relacionados (incluso si ya se predijeron exitosamente antes). Esto es útil, por ejemplo, cuando el número de niveles en un registro aumenta desde la última ejecución y esos niveles aún necesitan edades.\n\nIMPORTANTE: Si seleccionas ambos calc_AD_models_denovo y predict_ages_denovo como FALSE en tu primera ejecución de modelado edad-profundidad, el flujo puede pedirte temporalmente cambiarlos a TRUE en la consola (no tienes que modificar el archivo de configuración).\n\n\n\nLos modelos edad-profundidad se construyen usando puntos de control de cronología (normalmente fechas de radiocarbono) con profundidad conocida, edad estimada y su incertidumbre asociada. Cada registro puede y debe tener varios puntos guardados en la tabla de control de cronología. Cada punto de control tiene las siguientes propiedades:\n\nProfundidad\nEdad estimada\nError de la edad estimada\nTipo de punto de control de cronología\nCurva de calibración utilizada (necesaria para convertir edades de radiocarbono a edades de calendario; ¡ojo! las edades de radiocarbono no son edades de calendario verdaderas).\n\nEste script realiza varios pasos para preparar los registros para el modelado edad-profundidad:\n\nCrear y adjuntar las curvas de calibración necesarias\nSeleccionar los tipos preferidos de puntos de control de cronología\nPreparar tablas de cronología (incluido corregir problemas con porcentaje de carbono si es necesario)\n\n\n\nLas curvas de calibración se asignan a cada punto de control según varios criterios. Si un punto de control tiene un tipo marcado para calibrar (ver sección siguiente), la curva se asigna según la posición geográfica del registro. Solo los puntos de control con edades de radiocarbono sin calibrar requieren recalibración. FOSSILPOL incluye un shapefile basado en la figura 7 de Hogg et al (2020) para asignar correctamente IntCal20, SHCal20 y una curva mixta. Se sigue la recomendación: “…el uso de (i) IntCal20 para áreas al norte de la ITCZ en junio-agosto (líneas discontinuas en la Figura 7) que reciben masas de aire del hemisferio norte durante todo el año, (ii) SHCal20 para áreas al sur de la ITCZ en diciembre-febrero (líneas punteadas en la Figura 7) que reciben masas de aire del hemisferio sur durante todo el año, y (iii) una curva mixta para áreas entre las dos posiciones estacionales de la ITCZ mostradas en la Figura 7, que reciben masas de aire del norte en diciembre-febrero y masas de aire del sur en junio-agosto”. FOSSILPOL también incluye una curva mixta construida con el paquete {rcarbon} con una proporción de contribución de la curva de 1:1. Consulte más información sobre el uso de la curva de calibración mixta.\nTodas las curvas de calibración tienen un límite de edad, es decir, solo pueden usarse para ciertas edades. Las curvas de calibración de radiocarbono actualmente no cubren edades mayores a 55 mil años. Para edades más jóvenes, durante el último siglo, existen problemas con el radiocarbono atmosférico y debe usarse un conjunto distinto de curvas (debido a las detonaciones nucleares en los 50-60, que alteraron la señal atmosférica). Si el punto de control tiene una edad de radiocarbono menor a 200 años BP, se usa una curva post-bomba (ver más arriba). Al igual que las curvas normales, la posición geográfica determina qué curva post-bomba asignar.\nLas fechas modernas de radiocarbono se calibran usando una de las curvas post-bomba (nh_zone_1, nh_zone_2, nh_zone_3, sh_zone_1_2, sh_zone_3), siguiendo a Hua et al., 2013 y enlace. El flujo asignará la curva adecuada automáticamente (ver función IntCal::copyCalibrationCurve()). Si detecta fechas modernas, mostrará los registros y aplicará la conversión usando el paquete {IntCal}.\n\n\n\nCada punto de control tiene varias propiedades: ID único, profundidad, edad, error, espesor y tipo de control (ej. radiocarbono, biostratigráfico, laminaciones anuales, tefra). Cada tipo tiene diferentes incertidumbres de edad. Por ejemplo, muchos registros antiguos se basan en técnicas indirectas (biostratigráficas, tefra, etc.) y pueden tener grandes incertidumbres. Neotoma tiene más de 50 tipos distintos de puntos de control, que abarcan geocronología (ej. plomo-210, radiocarbono, uranio), escala temporal relativa (por ejemplo, MIS5e, Heinrich Stadial 1, Late Wisconsin event), estratigráfica (por ejemplo, eventos bioestratigráficos como la introducción de taxones antropogénicos), cultural (por ejemplo, European Settlement Horizon), otros métodos de datación absoluta (por ejemplo, laminaciones anuales, fecha de recolección) y otros métodos de datación (por ejemplo, extrapolación o conjeturas). Solo los puntos de control cronológico en edades radiocarbónicas sin calibrar requieren recalibración con las curvas de calibración, ya que la mayoría, si no todos, los demás puntos de control estarán en edades calendáricas y no se debe implementar ninguna recalibración.\nEl usuario puede elegir qué tipos de control aceptar “tal cual” y cuáles calibrar (un punto stop-check, Fig. 2). El flujo genera automáticamente una lista con todos los puntos de control detectados, incluyendo columnas include y calibrate. En la primera, el usuario indica si se debe incluir el punto; en la segunda, si debe calibrarse.\n\n\n\nLas tablas de control de cronología deben pasar varios ajustes definidos por el usuario:\n\nfiltrar tipos de puntos de control no deseados seleccionados por el usuario (stop-check)\nfiltrar registros que no cumplan el número mínimo de puntos de control (min_n_of_control_points en el archivo de configuración, por defecto = 2, Fig. 2 - criterio config 8)\ncorregir valores ausentes con default_thickness (por defecto = 1, Fig. 2 - criterio config 9) y default_error (por defecto = 100, Fig. 2 - criterio config 10)\nfiltrar puntos de control con errores demasiado grandes (max_age_error en el archivo de configuración; por defecto = 3000 años, Fig. 2 - criterio config 11)\neliminar puntos de control duplicados en términos de edad y/o profundidad\nen varios casos, el punto de control de la parte superior del núcleo es de tipo guess. El usuario puede especificar que el tipo guess solo sea aceptado hasta cierta profundidad usando guess_depth (por defecto es 10 cm, Fig. 2 - criterio config 12)\n\nAdemás, el número y la distribución de estos puntos pueden indicar la incertidumbre temporal de las edades (Giesecke et al. 2014, Flantua et al. 2016). Un registro con pocos puntos en el periodo de interés tendrá mayor incertidumbre.\n\n\n\nExisten tres maneras de reportar fechas post-bomba de radiocarbono: 1) fechas modernas (&lt;0 F14C años); 2) porcentaje de carbono moderno (pMC, normalizado a 100%); y 3) fracción de radiocarbono (F14C, normalizado a 1; Reimer et al. 2004). Actualmente no hay manera directa de saber si las fechas de Neotoma están en pMC o F14C. Si se detectan, el flujo exporta los registros sospechosos y el usuario debe especificar cuáles deben retrotransformarse (stop-check, Fig. 2). Para los seleccionados, se convierten los valores pMC a edades negativas con IntCal::pMC.age(), tras lo cual se usan las curvas post-bomba para calibrar a edades de calendario.\nAunque F14C se recomienda como estándar, en la práctica la mayoría se reporta como fechas normales de radiocarbono o como pMC. El flujo actualmente no gestiona F14C ya que no se han detectado casos. Si se encuentra con otras fuentes, se puede transformar usando el paquete {IntCal}.\n\n\n\n\nLos modelos edad-profundidad individuales se estiman con el paquete {Bchron}, que estima la trayectoria probabilística bayesiana (modelo no paramétrico). Es apto para diversas combinaciones de tipos de puntos de control, outliers y reversals.\nSi hay muchas edades a profundidades cercanas, pueden producirse problemas de inicialización y Bchron podría no converger. En ese caso, el grosor de los puntos duplicados se aumenta automáticamente por 0.01 (ver argumento artificialThickness en Bchron::Bchronology()).\n\n\nComo crear modelos edad-profundidad para muchos registros puede ser intensivo, el flujo usa computación paralela. Detecta automáticamente los núcleos de la máquina (ajustable con number_of_cores en el archivo de configuración, Fig. 2 - criterio config 14). Los modelos se crean en lotes, con el tamaño determinado por el número de núcleos (batch size, Fig. 2 - criterio config 13; por defecto depende de number_of_cores). Si number_of_cores es 1, no usa el modo lote.\nSi el cálculo del lote falla, el flujo omite ese lote y sigue con los demás. El usuario puede ajustar el tiempo de espera con el argumento time_per_record en RFossilpol::chron_recalibrate_ad_models().\nCada lote se intenta tres veces (ajustable con batch_attempts). Si se detiene el modelado, se usan los lotes exitosos previamente guardados. Si algún registro causa que R se congele completamente, su ID se guarda automáticamente en el archivo Crash (/Data/Input/Chronology_setting/Bchron_crash/) y se omite en futuras ejecuciones. Se recomienda revisar ese dataset en detalle.\n\n\n\nEn el archivo de configuración, el número de iteraciones es 50,000 por defecto, descartando las primeras 10,000 (burn-in) y guardando cada iteración subsiguiente con un salto de 40 (thinning) (Fig. 2 - criterios config 15, 16, 17). El usuario puede cambiar esto con iteration_multiplier (Fig. 2 - criterio config 18). Así, se obtienen 1000 ((50k - 10k) / 40) valores posteriores. El número por defecto es robusto pero se puede aumentar (aunque incrementará el tiempo de espera).\nHay que tener en cuenta que modelar cientos de registros con muchas iteraciones es intensivo y puede llevar decenas de horas o días.\n\n\n\n\nCon un modelo exitoso, se estiman las edades de cada nivel. El flujo calculará la edad y la estimación de error (que engloba el 95% de los valores posteriores: límite superior e inferior). Como {Bchron} es probabilístico, es posible obtener posibles edades. Para ello, se extraen varios valores (por defecto = 1000), se calculan cuartiles, usando el cuantil 50 como edad final y los cuantiles 2.5 y 97.5 como límites. Todo se guarda como matriz de incertidumbre de edad (age_uncertainty). Todo el proceso es automático.\n\n\n\nLa representación visual de todos los modelos edad-profundidad se guarda como PDFs en /Outputs/Figures/Chronologies/, divididos por región. Las propiedades se pueden cambiar en el archivo de configuración (image_width, image_height, image_units, image_dpi, text_size, line_size). Se recomienda revisarlas para buscar errores grandes, hiatos o extrapolaciones extremas.\n\n\n\nLas edades predichas se enlazan con todos los registros de las diferentes fuentes (Secciones I-III). Los niveles de cada registro se ordenan por edades predichas y el mismo orden se aplica a las tablas de conteos de polen.\n\n\n\n\n\n\n\n\nRun_01_05.R - ejecuta todos los scripts dentro de esta carpeta\n01_Harmonisation.R - prepara todas las tablas de armonización y armoniza los conteos brutos.\n\n\n\nEl objetivo de la armonización taxonómica es estandarizar todos los nombres a nivel de sitio a los mismos morfotipos de polen (conjunto de morfotipos de polen y esporas usados para todos los registros), y así reducir el efecto de la incertidumbre taxonómica y la complejidad nomenclatural (ver literatura relevante en el Apéndice 1 de Flantua et al. 2023). Para ello, se puede crear una tabla de armonización que agrupa los morfotipos en el mayor nivel taxonómic que es muy probable que la mayoría de los analistas de polen lo identifiquen.\n\n\n\nPrimero, el flujo de trabajo revisa las regiones de armonización presentes en los datos, definidas por el shapefile (ver Entrada de datos y Sección III), y confirma que exista una tabla de armonización por región (un punto stop-check, Fig. 2). Si falta alguna tabla (o se ejecuta por primera vez), el flujo crea automáticamente una tabla por región, con todos los nombres crudos de taxones de todos los registros de esa región. Cabe destacar que, para simplificar, nos referimos aquí a “nombres de taxón”, pero la identificación suele realizarse a nivel de familia o género, y se denominan mejor morfotipos.\nCada tabla de armonización tiene dos columnas:\n\ntaxon_name es el nombre original del taxón (morfotipo) en formato computacional (snake_case)\nlevel 1, que se usa para agrupar varios taxones (morfotipos) en unidades armonizadas, específicas del proyecto.\n\nPara enlazar los nombres con la visualización original de Neotoma, el usuario puede usar la taxa_reference_table (ver proceso de limpieza de nombres).\nEl usuario puede también definir qué taxones deben eliminarse totalmente durante la armonización (marcados como delete), en caso de errores taxonómicos o proxies no deseados (ej. esporas). Se pueden añadir columnas extra (ej. level_2) y especificar qué niveles incluir ajustando el argumento harm_name en la función RFossilpol::harmonise_all_regions().\nCon estas tablas, cada conjunto se armoniza para que todos los taxones que pertenezcan al mismo taxón armonizado (morfotipo) se sumen en cada nivel; esto aplica tanto para datos de conteo como de porcentaje. El proceso incluye una verificación automática de éxito de la armonización, revisando el número total de granos antes y después de armonizar (puede desactivarse cambiando el argumento pollen_grain_test a FALSE en la función RFossilpol::harmonise_all_regions()).\n\n\n\n\n\n\n\n\nRun_01_06.R - ejecuta todos los scripts dentro de esta carpeta\n01_Level_filtering.R - filtra niveles y registros según los criterios definidos por el usuario en el archivo de configuración\n\n\n\nPara obtener una compilación comprensiva de múltiples registros de polen fósil, mejorar la calidad general y responder preguntas de investigación de forma fiable, recomendamos reducir aún más la selección filtrando niveles individuales y/o registros completos. Todos los criterios de filtrado pueden ser ajustados por el usuario en el archivo de configuración:\n\nfilter_by_pollen_sum (Fig. 2 - criterio config 20) - si es TRUE, el flujo utiliza la cantidad de granos de polen contados en cada nivel como indicador de calidad.\nfilter_by_age_limit (Fig. 2 - criterio config 24) - si es TRUE, se filtran registros que no cubran el periodo de interés definido por el usuario.\nfilter_by_extrapolation (Fig. 2 - criterio config 25) - si es TRUE, se filtran niveles según el número de años extrapolados respecto al último punto de control de cronología usado.\nfilter_by_interest_region (Fig. 2 - criterio config 27) - si es TRUE, se filtran niveles mayores a end_of_interest_period.\nfilter_by_number_of_levels (Fig. 2 - criterio config 28) - si es TRUE, se filtran registros según el número de niveles.\n\nAdemás, se pueden activar dos opciones más:\n\nuse_age_quantiles (Fig. 2 - criterio config 30) - si es TRUE, se usa el cuantil 95 de la edad en el filtrado (incertidumbre).\nuse_bookend_level (Fig. 2 - criterio config 31) - si es TRUE, se deja un nivel adicional más allá de la edad más antigua del periodo de interés.\n\n\n\n\n\n\nEl número de granos contados en cada nivel es un índice de calidad. Para una representación fiable de la vegetación, se recomienda contar más de 300 granos (Moore et al., 1991), aunque pueden usarse otros criterios (por ejemplo, 150; ver Djamali & Cilleros, 2020). En regiones árticas puede bastar con c. 100, en sitios mediterráneos puede llegar a 1000 (Birks & Birks, 1980), pero la preferencia del analista es clave. Números bajos suelen deberse a limitaciones de tiempo, pero también a fenómenos de preservación. Dado que el poder inferencial estadístico es proporcional al tamaño de muestra, recomendamos definir un mínimo de granos en cada nivel. Luego, se puede aceptar un registro solo si X% (por defecto 50, Fig. 2 - criterio config 23) de los niveles cumple el número aceptable.\n\n\n\nSegún el enfoque temporal, solo un subconjunto de registros será de interés. Por tanto, registros que no cubran el periodo de interés serán filtrados si filter_by_age_limit == TRUE.\n\n\n\nLa extrapolación de edades a muestras más allá del último punto de control incrementa la incertidumbre. Recomendamos seleccionar una extrapolación máxima (ej. 5000 años) respecto al último punto de control; niveles más viejos serán filtrados si filter_by_extrapolation == TRUE.\n\n\n\nNiveles fuera del periodo de interés (end_of_interest_period) serán filtrados si filter_by_interest_region == TRUE.\n\n\n\nEl número total de niveles es importante para futuros análisis. Registros con pocos niveles aportan poco y pueden ser fuentes de valores atípicos. Se recomienda definir un número mínimo (min_n_levels, Fig. 2 - criterio config 29); se filtrará si filter_by_number_of_levels == TRUE.\n\n\n\n\n\n\n\n\n\nRun_01_07.R - ejecuta todos los scripts dentro de esta carpeta\n01_Pollen_diagrams.R - guarda los diagramas de polen de todos los registros\n02_Save_assembly.R - guarda el ensamblado de datos con las variables seleccionadas\n03_Save_references.R - guarda referencias y metadatos\n\n\n\nLos diagramas de polen para todos los registros se crean usando el paquete {rioja}. Los datos armonizados se transforman automáticamente en proporción relativa para graficar. Los diagramas se guardan en /Outputs/Figures/Pollen_diagrams/, divididos por Región.\nLa función RFossilpol::plot_all_pollen_diagrams() genera automáticamente un PDF de los diagramas, listos para imprimir. El eje Y es, por defecto, la edad de los niveles (puede cambiarse a profundidad con el argumento y_var). El máximo de taxones por página se ajusta con max_taxa (por defecto, 20). Además, la función omite taxones muy raros, definido por min_n_occur.\n\n\n\nUna compilación armonizada y estandarizada, lista para análisis, se produce y guarda en /Outputs/Data/ como tibble (rds). El usuario puede seleccionar qué columnas deben estar presentes en la compilación final estableciendo select_final_variables == TRUE en el archivo de configuración. El flujo pedirá al usuario en la consola de R si incluir cada variable.\n\n\n\nEl flujo guarda todos los metadatos y la información de citación necesarios para crear la compilación de datos. Todos los resultados están en /Outputs/Meta_and_references/. La función RFossilpol::proc_save_references() lo hace automáticamente, pero el usuario puede especificar qué información guardar usando el argumento user_sel_variables. Por defecto incluye:\n\n\"meta_table\" - tabla de metadatos (data_assembly_meta.csv) contiene por defecto (la lista puede alterarse ajustando variables finales por select_final_variables):\n\nlista de todos los registros en la compilación final\nubicación geográfica\nambiente de depósito\nregión continental asignada\nregión de armonización asignada\nnúmero final de niveles\nnúmero de puntos de control de cronología usados en el modelado edad-profundidad\ncurvas de calibración asignadas\nlímites de edad de cada registro por fuente (Neotoma u otra)\nDOI (de Neotoma)\n\n\"author_table\" - tabla de referencias (authors_meta.csv) con información sobre los conjuntos de datos utilizados, el principal contribuyente y su contacto.\n\"affiliation_table\" - si se provee afiliación con datos distintos de Neotoma, la tabla de afiliaciones (affiliation_table) enlaza autores y afiliaciones.\n\"graphical_summary\" - PDF (graphical_summary*.pdf) con tres figuras usando RFossilpol::plot_graphical_summary():\n\nmapa de ubicación geográfica de los registros\ngráfico de bastones con el número de registros por grupo\nlímites de edad de los registros (línea por registro)\n\n\"reproducibility_bundle\" - un zip (reproducibility_bundle.zip) con el archivo de configuración, todas las tablas stop-check, y todos los shapefiles. La idea es aumentar la reproducibilidad; este zip puede compartirse al publicar un proyecto creado con el flujo FOSSILPOL, o durante revisión para obtener feedback detallado antes de la publicación."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Este sitio web presenta toda la información necesaria sobre el flujo de trabajo FOSSILPOL, que tiene como objetivo procesar y estandarizar datos globales de polen paleoecológico.\n\n\nEl flujo de trabajo FOSSILPOL ha sido desarrollado durante el proyecto ERC denominado Humans on Planet Earth (HOPE) por el equipo de la University of Bergen:\nSuzette G.A. Flantua*, Ondrej Mottl*, Vivian Felde*, Kuber P. Bhatta*, Hilary Birks, John-Arvid Grytnes, Alistair Seddon, H. John B. Birks\n* autores principales compartidos\nOndřej Mottl es el principal responsable del proyecto FOSSILPOL\n\n\n\n\n\n  \n\n\n\n\n\nEl proyecto consta de varias secciones:\n\nA guide to the processing and standardisation of global palaeoecological data for large-scale syntheses using fossil pollen – Una publicación de acceso abierto en Global Ecology and Biogeography (Flantua et al. 2023)\nFOSSILPOL workflow – Una herramienta para procesar múltiples registros de polen fósil y crear una compilación de datos completa y estandarizada, lista para análisis multi-registro y multi-proxy (programado en el entorno R)\n{RFossilpol} package – Un paquete de R desarrollado específicamente para proporcionar herramientas y funciones para el flujo de trabajo FOSSILPOL\nSitio web – El centro principal de toda la información sobre el proyecto FOSSILPOL, incluyendo una guía paso a paso para los usuarios, con una descripción de las funciones más importantes y los criterios para usuarios a lo largo del flujo de trabajo\nEjemplo de Escandinavia – Un ejemplo de caso de estudio del flujo de trabajo FOSSILPOL aplicado a registros de polen fósil del norte de Europa\nIssue tracker – Repositorio específico de GitHub para gestionar todos los problemas detectados en el flujo de trabajo FOSSILPOL\nFuturas actualizaciones – Panorama de las futuras actualizaciones que planeamos realizar en el flujo de trabajo FOSSILPOL y en el paquete de R\n\n\n\n\n\nInformación general – Información sobre cómo obtener, configurar y ejecutar el proyecto FOSSILPOL\nGuía paso a paso – Información detallada sobre los pasos individuales del procesamiento de datos\n¡Ponte en contacto! – Información sobre la comunidad, futuras actualizaciones, reporte de problemas y posibles colaboraciones\nRecursos – Materiales adicionales relacionados con el proyecto FOSSILPOL.\n\n\n\n\n\nFlujo de trabajo FOSSILPOL: \nPaquete de R {RFossilpol}:"
  },
  {
    "objectID": "index.html#resumen",
    "href": "index.html#resumen",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Este sitio web presenta toda la información necesaria sobre el flujo de trabajo FOSSILPOL, que tiene como objetivo procesar y estandarizar datos globales de polen paleoecológico.\n\n\nEl flujo de trabajo FOSSILPOL ha sido desarrollado durante el proyecto ERC denominado Humans on Planet Earth (HOPE) por el equipo de la University of Bergen:\nSuzette G.A. Flantua*, Ondrej Mottl*, Vivian Felde*, Kuber P. Bhatta*, Hilary Birks, John-Arvid Grytnes, Alistair Seddon, H. John B. Birks\n* autores principales compartidos\nOndřej Mottl es el principal responsable del proyecto FOSSILPOL"
  },
  {
    "objectID": "index.html#secciones-del-proyecto",
    "href": "index.html#secciones-del-proyecto",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "El proyecto consta de varias secciones:\n\nA guide to the processing and standardisation of global palaeoecological data for large-scale syntheses using fossil pollen – Una publicación de acceso abierto en Global Ecology and Biogeography (Flantua et al. 2023)\nFOSSILPOL workflow – Una herramienta para procesar múltiples registros de polen fósil y crear una compilación de datos completa y estandarizada, lista para análisis multi-registro y multi-proxy (programado en el entorno R)\n{RFossilpol} package – Un paquete de R desarrollado específicamente para proporcionar herramientas y funciones para el flujo de trabajo FOSSILPOL\nSitio web – El centro principal de toda la información sobre el proyecto FOSSILPOL, incluyendo una guía paso a paso para los usuarios, con una descripción de las funciones más importantes y los criterios para usuarios a lo largo del flujo de trabajo\nEjemplo de Escandinavia – Un ejemplo de caso de estudio del flujo de trabajo FOSSILPOL aplicado a registros de polen fósil del norte de Europa\nIssue tracker – Repositorio específico de GitHub para gestionar todos los problemas detectados en el flujo de trabajo FOSSILPOL\nFuturas actualizaciones – Panorama de las futuras actualizaciones que planeamos realizar en el flujo de trabajo FOSSILPOL y en el paquete de R"
  },
  {
    "objectID": "index.html#páginas-del-sitio-web",
    "href": "index.html#páginas-del-sitio-web",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Información general – Información sobre cómo obtener, configurar y ejecutar el proyecto FOSSILPOL\nGuía paso a paso – Información detallada sobre los pasos individuales del procesamiento de datos\n¡Ponte en contacto! – Información sobre la comunidad, futuras actualizaciones, reporte de problemas y posibles colaboraciones\nRecursos – Materiales adicionales relacionados con el proyecto FOSSILPOL."
  },
  {
    "objectID": "index.html#versiones-actuales",
    "href": "index.html#versiones-actuales",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Flujo de trabajo FOSSILPOL: \nPaquete de R {RFossilpol}:"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Aquí presentamos una guía sobre cómo obtener y configurar el flujo de trabajo FOSSILPOL, que es un flujo de trabajo modular basado en R para procesar múltiples registros de polen fósil y crear una compilación de conjuntos de datos completa y estandarizada, lista para análisis multi-registro y multi-proxy a diferentes escalas espaciales y temporales (Fig. 1). La guía general se describe en la publicación titulada A guide to the processing and standardisation of global palaeoecological data for large-scale syntheses using fossil pollen, por Flantua, S.G.A., Mottl, O., Felde, V.A., Bhatta, K.P., Birks, H.H., Grytnes, J-A., Seddon, A.W.R., Birks H.J.B. (2023) en Global Ecology and Biogeography.\n\n\n\n\n \n\n\n\nEl flujo de trabajo FOSSILPOL está programado como un RStudio project (en el R programming language), que debe ser personalizado por el usuario según su proyecto de investigación específico.\nEl flujo de trabajo FOSSILPOL ha sido desarrollado para procesar datos de polen fósil en el proyecto ERC denominado Humans on Planet Earth (HOPE) por el equipo de la University of Bergen.\nEl logo de FOSSILPOL y la Figura 1 han sido creados por el increíble MilanTvM\n\n\n\n\n\n\nEl flujo de trabajo FOSSILPOL (denominado “el Flujo de Trabajo” en adelante) es accesible de dos maneras:\n\nSi el usuario tiene una cuenta en GitHub, la forma más sencilla es crear su propio repositorio de GitHub usando esta plantilla de GitHub. Más detalles sobre cómo usar plantillas de GitHub se encuentran en GitHub Docs.\nEl usuario puede descargar la última Release del Flujo de Trabajo como archivo zip desde la página de Releases del Flujo de Trabajo de FOSSILPOL.\n\nEl proyecto de R consiste en códigos con scripts y funciones individuales. Todos los scripts se almacenan en la carpeta R/. Después de obtener el flujo de trabajo, el proyecto R de FOSSILPOL tendrá la siguiente estructura:\n\n\n\nproject\n│\n│   README.md\n│   Rprofile\n│   gitignore  \n│   Workflow_template.Rproj\n│\n└───Data\n│   │\n│   └───Input\n│       │\n│       └───Spatial\n│           │\n│           └───Biomes_shapefile   \n│           │   │\n│           │   └───WWF\n│           │\n│           └───Calibration_curves_shapefile   \n│           │\n│           └───Countries_shapefile\n│           │  \n│           └───Harmonisation_regions_shapefile\n│           │\n│           └───Postbomb_shapefile\n│           │\n│           └───Regions_shapefile\n│\n└───R\n│   │\n│   │   ___Init_project___.R\n│   │   00_Config_file.R\n│   │\n│   └───01_Data_processing\n│   │   │   │\n│   │   │   │   Master_run_01.R\n│   │   │\n│   │   └───01_Neotoma_source\n│   │   │   │\n│   │   │   │   Run_01_01.R\n│   │   │   │   01_Download_neotoma.R\n│   │   │   │   02_Extract_samples.R\n│   │   │   │   03_Filter_dep_env.R\n│   │   │   │   04_Extract_chron_control_tables.R\n│   │   │   │   05_Extract_raw_pollen_data.R\n│   │   │   \n│   │   └───02_Other_source\n│   │   │   │\n│   │   │   │   Run_01_02.R\n│   │   │   │   01_Import_other_data.R\n│   │   │\n│   │   └───03_Merging_and_geography\n│   │   │   │\n│   │   │   │   Run_01_03.R\n│   │   │   │   01_Merge_datasets.R\n│   │   │\n│   │   └───04_Chronologies\n│   │   │   │\n│   │   │   │   Run_01_04.R\n│   │   │   │   01_Prepare_chron_control_tables.R\n│   │   │   │   02_Run_age_depth_models.R\n│   │   │   │   03_Predict_ages.R\n│   │   │   │   04_Save_AD_figures.R\n│   │   │   │   05_Merge_chron_output.R\n│   │   │\n│   │   └───05_Harmonisation\n│   │   │   │\n│   │   │   │   Run_01_05.R\n│   │   │   │   01_Harmonisation.R\n│   │   │\n│   │   └───06_Main_filtering\n│   │   │   │\n│   │   │   │   Run_01_06.R\n│   │   │   │   01_Level_filtering.R\n│   │   │\n│   │   └───07_Outputs\n│   │       │\n│   │       │   Run_01_07.R\n│   │       │   01_Pollen_diagrams.R\n│   │       │   02_Save_assembly.R\n│   │       │   03_Save_references.R\n│   │\n│   └───02_Main_analyses\n│   │   │\n│   │   │   Master_run_02.R\n│   │\n│   └───03_Supplementary_analyses\n│   │   │\n│   │   │   Master_run_03.R\n│   │\n│   └───Functions\n│       │\n│       │ example_function.R\n│\n└───renv\n    │\n    │   gitignore\n    │   activate.R\n    │   library_list.lock\n    │   settings.dcf\n\n\n\n\nUna vez que el usuario obtiene su versión del Flujo de Trabajo, hay varios pasos a seguir antes de usarlo:\n\nActualiza R y R-studio IDE. Hay muchas guías sobre cómo hacerlo (por ejemplo, aquí)\nEjecuta todos los pasos individuales con el script ___Init_project___.R. Esto preparará todos los paquetes de R utilizando el paquete {renv}, que gestiona las dependencias de R de tus proyectos. Principalmente instalará dos paquetes principales de R: {RFossilpol} y {RUtilpol} y todas sus dependencias. RFossilpol ha sido desarrollado específicamente para el flujo de trabajo y la última versión se instala automáticamente en la etapa de configuración del proyecto. Esto es importante ya que la versión del paquete debe coincidir con la versión del Flujo de Trabajo. Por lo tanto, no recomendamos actualizar el paquete después de la instalación. Ten en cuenta que instalar todos los paquetes puede llevar un tiempo considerable.\nConfigura tus preferencias editando el script 00_Config_file.R (denominado “Config file” en adelante). El Config file es un script donde todos los ajustes (configuraciones) y criterios utilizados en todo el proyecto están predefinidos por el usuario antes de ejecutar el Flujo de Trabajo. Además, prepara la sesión actual cargando los paquetes requeridos y guardando todos los ajustes durante el proyecto. Los puntos en el Config file que requieren atención del usuario están marcados con “[USER]”, lo que significa que estos son criterios que deben ser revisados por el usuario. Más información sobre el Config file se encuentra en la sección del sitio web Guía paso a paso. Los puntos cruciales son:\n\ndata_storage_path dentro de la sección “2. Fecha actual y directorio de trabajo” – como el Flujo de Trabajo produce varios archivos grandes, el usuario puede especificar el directorio donde se almacenarán dichos archivos. Ten en cuenta que el lugar predeterminado es dentro del proyecto.\nsección “5. Definir variables” – estas son las variables importantes para la selección y el filtrado de datos para obtener la compilación final de datos.\n\nEjecuta R/01_Data_processing/Master_run_01.R para ejecutar toda la parte de procesamiento de datos del proyecto (prepárate para los “stop-checks”). Alternativamente, el usuario puede ejecutar cada script de manera individual. Una vez resueltos todos los stop-checks, el Flujo de Trabajo se puede ejecutar completo para producir la compilación estandarizada final de datos, lista para análisis multi-registro y multi-proxy.\nSi se desea, el usuario puede ejecutar scripts adicionales específicos de su proyecto (no proporcionados) en las carpetas 02_Main_analyses y 03_Supplementary_analyses para analizar la compilación de datos.\n\n\n\n\nEste Flujo de Trabajo está construido utilizando una cascada de scripts. Esto significa que Master_run_01.R, ubicado en la carpeta R/01_Data_processing/, ejecuta todos los scripts dentro de las subcarpetas de R/01_Data_processing/ y, a su vez, ejecuta sus propias subcarpetas (por ejemplo, R/01_Data_processing/01_Neotoma_source/Run_01_01.R ejecuta R/01_Data_processing/01_Neotoma_source/01_Download_neotoma.R, R/01_Data_processing/01_Neotoma_source/02_Extract_samples.R, …). Consulta el Bloque de código 2.\nPor lo tanto, un usuario puede ejecutar la sección de procesamiento de datos del proyecto ejecutando el script R/01_Data_processing/Master_run_01.R o ejecutar secciones individuales ejecutando scripts individuales dentro de las secciones. Un ejemplo alternativo es que el usuario puede ejecutar la subsección del Flujo de Trabajo completa ejecutando R/01_Data_processing/01_Neotoma_source/Run_01_01.R, y no R/01_Data_processing/01_Neotoma_source/01_Download_neotoma.R, y luego R/01_Data_processing/01_Neotoma_source/02_Extract_samples.R, etc.\n\n\n\nR\n│\n└───01_Data_processing\n        │\n        │   Master_run_01.R\n        │\n        └───01_Neotoma_source\n            │\n            │   Run_01_01.R\n                │\n                │   01_Download_neotoma.R\n                │   02_Extract_samples.R\n                │   03_Filter_dep_env.R\n                │   04_Extract_chron_control_tables.R\n                │   05_Extract_raw_pollen_data.R"
  },
  {
    "objectID": "about.html#información-general",
    "href": "about.html#información-general",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "Aquí presentamos una guía sobre cómo obtener y configurar el flujo de trabajo FOSSILPOL, que es un flujo de trabajo modular basado en R para procesar múltiples registros de polen fósil y crear una compilación de conjuntos de datos completa y estandarizada, lista para análisis multi-registro y multi-proxy a diferentes escalas espaciales y temporales (Fig. 1). La guía general se describe en la publicación titulada A guide to the processing and standardisation of global palaeoecological data for large-scale syntheses using fossil pollen, por Flantua, S.G.A., Mottl, O., Felde, V.A., Bhatta, K.P., Birks, H.H., Grytnes, J-A., Seddon, A.W.R., Birks H.J.B. (2023) en Global Ecology and Biogeography."
  },
  {
    "objectID": "about.html#cómo-obtener-el-flujo-de-trabajo",
    "href": "about.html#cómo-obtener-el-flujo-de-trabajo",
    "title": "FOSSILPOL project",
    "section": "",
    "text": "El flujo de trabajo FOSSILPOL (denominado “el Flujo de Trabajo” en adelante) es accesible de dos maneras:\n\nSi el usuario tiene una cuenta en GitHub, la forma más sencilla es crear su propio repositorio de GitHub usando esta plantilla de GitHub. Más detalles sobre cómo usar plantillas de GitHub se encuentran en GitHub Docs.\nEl usuario puede descargar la última Release del Flujo de Trabajo como archivo zip desde la página de Releases del Flujo de Trabajo de FOSSILPOL.\n\nEl proyecto de R consiste en códigos con scripts y funciones individuales. Todos los scripts se almacenan en la carpeta R/. Después de obtener el flujo de trabajo, el proyecto R de FOSSILPOL tendrá la siguiente estructura:\n\n\n\nproject\n│\n│   README.md\n│   Rprofile\n│   gitignore  \n│   Workflow_template.Rproj\n│\n└───Data\n│   │\n│   └───Input\n│       │\n│       └───Spatial\n│           │\n│           └───Biomes_shapefile   \n│           │   │\n│           │   └───WWF\n│           │\n│           └───Calibration_curves_shapefile   \n│           │\n│           └───Countries_shapefile\n│           │  \n│           └───Harmonisation_regions_shapefile\n│           │\n│           └───Postbomb_shapefile\n│           │\n│           └───Regions_shapefile\n│\n└───R\n│   │\n│   │   ___Init_project___.R\n│   │   00_Config_file.R\n│   │\n│   └───01_Data_processing\n│   │   │   │\n│   │   │   │   Master_run_01.R\n│   │   │\n│   │   └───01_Neotoma_source\n│   │   │   │\n│   │   │   │   Run_01_01.R\n│   │   │   │   01_Download_neotoma.R\n│   │   │   │   02_Extract_samples.R\n│   │   │   │   03_Filter_dep_env.R\n│   │   │   │   04_Extract_chron_control_tables.R\n│   │   │   │   05_Extract_raw_pollen_data.R\n│   │   │   \n│   │   └───02_Other_source\n│   │   │   │\n│   │   │   │   Run_01_02.R\n│   │   │   │   01_Import_other_data.R\n│   │   │\n│   │   └───03_Merging_and_geography\n│   │   │   │\n│   │   │   │   Run_01_03.R\n│   │   │   │   01_Merge_datasets.R\n│   │   │\n│   │   └───04_Chronologies\n│   │   │   │\n│   │   │   │   Run_01_04.R\n│   │   │   │   01_Prepare_chron_control_tables.R\n│   │   │   │   02_Run_age_depth_models.R\n│   │   │   │   03_Predict_ages.R\n│   │   │   │   04_Save_AD_figures.R\n│   │   │   │   05_Merge_chron_output.R\n│   │   │\n│   │   └───05_Harmonisation\n│   │   │   │\n│   │   │   │   Run_01_05.R\n│   │   │   │   01_Harmonisation.R\n│   │   │\n│   │   └───06_Main_filtering\n│   │   │   │\n│   │   │   │   Run_01_06.R\n│   │   │   │   01_Level_filtering.R\n│   │   │\n│   │   └───07_Outputs\n│   │       │\n│   │       │   Run_01_07.R\n│   │       │   01_Pollen_diagrams.R\n│   │       │   02_Save_assembly.R\n│   │       │   03_Save_references.R\n│   │\n│   └───02_Main_analyses\n│   │   │\n│   │   │   Master_run_02.R\n│   │\n│   └───03_Supplementary_analyses\n│   │   │\n│   │   │   Master_run_03.R\n│   │\n│   └───Functions\n│       │\n│       │ example_function.R\n│\n└───renv\n    │\n    │   gitignore\n    │   activate.R\n    │   library_list.lock\n    │   settings.dcf\n\n\n\n\nUna vez que el usuario obtiene su versión del Flujo de Trabajo, hay varios pasos a seguir antes de usarlo:\n\nActualiza R y R-studio IDE. Hay muchas guías sobre cómo hacerlo (por ejemplo, aquí)\nEjecuta todos los pasos individuales con el script ___Init_project___.R. Esto preparará todos los paquetes de R utilizando el paquete {renv}, que gestiona las dependencias de R de tus proyectos. Principalmente instalará dos paquetes principales de R: {RFossilpol} y {RUtilpol} y todas sus dependencias. RFossilpol ha sido desarrollado específicamente para el flujo de trabajo y la última versión se instala automáticamente en la etapa de configuración del proyecto. Esto es importante ya que la versión del paquete debe coincidir con la versión del Flujo de Trabajo. Por lo tanto, no recomendamos actualizar el paquete después de la instalación. Ten en cuenta que instalar todos los paquetes puede llevar un tiempo considerable.\nConfigura tus preferencias editando el script 00_Config_file.R (denominado “Config file” en adelante). El Config file es un script donde todos los ajustes (configuraciones) y criterios utilizados en todo el proyecto están predefinidos por el usuario antes de ejecutar el Flujo de Trabajo. Además, prepara la sesión actual cargando los paquetes requeridos y guardando todos los ajustes durante el proyecto. Los puntos en el Config file que requieren atención del usuario están marcados con “[USER]”, lo que significa que estos son criterios que deben ser revisados por el usuario. Más información sobre el Config file se encuentra en la sección del sitio web Guía paso a paso. Los puntos cruciales son:\n\ndata_storage_path dentro de la sección “2. Fecha actual y directorio de trabajo” – como el Flujo de Trabajo produce varios archivos grandes, el usuario puede especificar el directorio donde se almacenarán dichos archivos. Ten en cuenta que el lugar predeterminado es dentro del proyecto.\nsección “5. Definir variables” – estas son las variables importantes para la selección y el filtrado de datos para obtener la compilación final de datos.\n\nEjecuta R/01_Data_processing/Master_run_01.R para ejecutar toda la parte de procesamiento de datos del proyecto (prepárate para los “stop-checks”). Alternativamente, el usuario puede ejecutar cada script de manera individual. Una vez resueltos todos los stop-checks, el Flujo de Trabajo se puede ejecutar completo para producir la compilación estandarizada final de datos, lista para análisis multi-registro y multi-proxy.\nSi se desea, el usuario puede ejecutar scripts adicionales específicos de su proyecto (no proporcionados) en las carpetas 02_Main_analyses y 03_Supplementary_analyses para analizar la compilación de datos.\n\n\n\n\nEste Flujo de Trabajo está construido utilizando una cascada de scripts. Esto significa que Master_run_01.R, ubicado en la carpeta R/01_Data_processing/, ejecuta todos los scripts dentro de las subcarpetas de R/01_Data_processing/ y, a su vez, ejecuta sus propias subcarpetas (por ejemplo, R/01_Data_processing/01_Neotoma_source/Run_01_01.R ejecuta R/01_Data_processing/01_Neotoma_source/01_Download_neotoma.R, R/01_Data_processing/01_Neotoma_source/02_Extract_samples.R, …). Consulta el Bloque de código 2.\nPor lo tanto, un usuario puede ejecutar la sección de procesamiento de datos del proyecto ejecutando el script R/01_Data_processing/Master_run_01.R o ejecutar secciones individuales ejecutando scripts individuales dentro de las secciones. Un ejemplo alternativo es que el usuario puede ejecutar la subsección del Flujo de Trabajo completa ejecutando R/01_Data_processing/01_Neotoma_source/Run_01_01.R, y no R/01_Data_processing/01_Neotoma_source/01_Download_neotoma.R, y luego R/01_Data_processing/01_Neotoma_source/02_Extract_samples.R, etc.\n\n\n\nR\n│\n└───01_Data_processing\n        │\n        │   Master_run_01.R\n        │\n        └───01_Neotoma_source\n            │\n            │   Run_01_01.R\n                │\n                │   01_Download_neotoma.R\n                │   02_Extract_samples.R\n                │   03_Filter_dep_env.R\n                │   04_Extract_chron_control_tables.R\n                │   05_Extract_raw_pollen_data.R"
  },
  {
    "objectID": "get_in_touch.html",
    "href": "get_in_touch.html",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "Nos encantaría construir una comunidad en torno a FOSSILPOL y hay varias maneras de ponerse en contacto y crecer juntos.\n\n\nHemos creado GitHub Discussions como el centro principal de comunicación. ¿Tienes una pregunta? ¿Has pensado en una nueva funcionalidad genial? Escríbenos un mensaje. Esperamos que la página de Discusiones sirva como línea de comunicación tanto para los desarrolladores como entre los diferentes usuarios.\n\n\n\nNingún software está libre de problemas, y si encuentras un error desagradable utilizando este flujo de trabajo, utiliza la página de Issues para reportarlo.\nConsidera los siguientes pasos antes y al abrir un nuevo Issue:\n\n¿Tú o alguien más ya lo ha preguntado en GitHub Discussions? ¡La sección “Q&A” es perfecta para eso!\n¿Has comprobado que problemas similares ya hayan sido reportados? El rastreador de Issues tiene una función de filtro para buscar palabras clave en los Issues abiertos. Puedes reducir la búsqueda usando labels🏷️ como filtros. Consulta Labels para más información. Como regla general, no asignamos issues a nadie.\n\nPara abrir un nuevo Issue:\n\nHaz clic en el botón verde New issue en la esquina superior derecha y selecciona Bug report.\nDescribe tu problema con el mayor detalle posible. El issue debe indicar cuál es el problema, cuál debería ser el comportamiento esperado y, tal vez, sugerir una solución. Ten en cuenta que también puedes adjuntar archivos (por ejemplo, datos de ejemplo, código en R, etc.) o imágenes al issue.\nSelecciona una label🏷️ adecuada del menú desplegable llamado Labels.\nHaz clic en el botón verde Submit new issue y espera una respuesta.\n\n\n\n\nTambién usamos la página de Issues para solicitudes serias de nuevas funcionalidades. Si alguna discusión en el portal GitHub Discussions lleva a una función bien definida que te gustaría implementar, puedes enviarla como feature request:\n\nVe a la página de Issues\nHaz clic en el botón verde New issue en la esquina superior derecha y selecciona Feature request.\nDescribe la funcionalidad con el mayor detalle posible. ¿Cuál es el comportamiento esperado? ¿Qué paquetes deberíamos usar? Ten en cuenta que también puedes adjuntar archivos o imágenes al Issue.\nSelecciona una label🏷️ adecuada del menú desplegable llamado Labels.\nHaz clic en el botón verde Submit new issue y espera una respuesta.\n\n\n\n\nEl proyecto FOSSILPOL está concebido como un software que recibirá actualizaciones para mejorar continuamente.\nSomos conscientes de las funciones y características que nos gustaría implementar en el futuro.\nConsulta las actualizaciones futuras previstas en project future updates. Las tres etapas de la solicitud son:\n\n“next version” – una función que se implementará en la próxima versión de FOSSILPOL\n“future” – una función que probablemente se implementará en una de las próximas versiones de FOSSILPOL\n“in consideration” – una función que podría implementarse, pero no es prioritaria\n\nSi hay alguna funcionalidad que te gustaría implementar, primero consulta el Issue Tracker y mira si alguien ya la ha sugerido y dale un voto positivo si ya está allí. Antes de cada lanzamiento de versión, implementaremos la funcionalidad más votada.\nNuestro objetivo es actualizar la lista regularmente.\n\n\n\nEl proyecto FOSSILPOL está concebido como un software que recibirá actualizaciones para mejorar continuamente.\nAgradecemos la ayuda :sparkling_heart: y gracias solo por considerar contribuir a FOSSILPOL.\nPara asegurarnos de mantener la más alta calidad de código, debemos cumplir algunas directrices estrictas. Por favor, lee este documento para ayudarte a comenzar.\nSi deseas reportar un bug, sugerir mejoras o solicitar una nueva funcionalidad, dirígete a la sección de Issues.\n\n\nUsamos el sistema de control de versiones Git para gestionar los desarrollos en el repositorio alojado en GitHub. Si eres nuevo en Git o GitHub, por favor revisa el GitHub Bootcamp para ponerte al día.\nSi ya conoces Git y GitHub, por favor revisa Submitting Pull Requests.\n\n\n\nAunque tenemos nuestro propio estilo de codificación y no seguimos ningún estándar disponible en la web, sí mantenemos cierta uniformidad.\nSi olvidamos mencionar algún caso particular, siempre debes seguir este procedimiento:\n\nMira cómo se hace en el código fuente.\nConsulta qué dice la convención de Advanced R by Hadley Wickham y elige algo que se asemeje al código base.\nSi todo lo demás falla, pregunta en GitHub Discussions\n\n\n\n\nTodos los cambios a FOSSILPOL deben ser en forma de pull request (también conocidos como PR). Si no estás familiarizado con los pull requests, por favor lee esto.\nEste es el proceso recomendado:\n\nHaz un fork del repositorio para que puedas hacer tus cambios sin afectar el proyecto original hasta que estés listo para fusionarlos. Consulta la Guía para forking\nTrabaja sobre la rama (nombrada según la próxima versión, si existe).\nHaz commit de tus actualizaciones cuando estés satisfecho con ellas. Consulta la guía de contribución para los mensajes de commit.\nCuando termines los cambios, crea un PR\n\nHaz clic en “Ready for review” para que podamos revisar tu PR. Esta plantilla ayuda a los revisores a entender tus cambios, así como el propósito de tu pull request.\nNo olvides vincular el PR al Issue si estás resolviendo uno.\nHabilita la casilla para permitir ediciones por parte de los mantenedores para que la rama pueda ser actualizada para una fusión. Una vez que envíes tu PR, un miembro del equipo HOPE revisará tu propuesta. Podemos hacer preguntas o solicitar información adicional.\nEs posible que pidamos cambios antes de poder fusionar el PR, ya sea usando cambios sugeridos o comentarios en el pull request. Puedes aplicar los cambios sugeridos directamente desde la interfaz de usuario (UI). Puedes hacer cualquier otro cambio en tu fork, y luego hacer commit a tu rama.\nA medida que actualices tu PR y apliques cambios, marca cada conversación como resuelta\nSi tienes problemas de fusión, revisa este tutorial de git para ayudarte a resolver conflictos de fusión y otros problemas.\n\n\nAntes de enviar un pull request, asegúrate de seguir todas las pautas a continuación mientras trabajas en tus cambios:\n\nCada pull request debe intentar lograr una sola tarea general.\nTodo el trabajo debe realizarse en una rama con un nombre descriptivo relacionado con la tarea general (por ejemplo, fix_bug_x o add_feature_y). Cada commit debe lograr una pequeña subtarea y debe ser explicable en una o dos frases.\nCada commit debe tener un mensaje descriptivo.\nDebes asegurarte de que tu código pase todas las pruebas antes de hacer commit."
  },
  {
    "objectID": "get_in_touch.html#contáctanos",
    "href": "get_in_touch.html#contáctanos",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "Hemos creado GitHub Discussions como el centro principal de comunicación. ¿Tienes una pregunta? ¿Has pensado en una nueva funcionalidad genial? Escríbenos un mensaje. Esperamos que la página de Discusiones sirva como línea de comunicación tanto para los desarrolladores como entre los diferentes usuarios."
  },
  {
    "objectID": "get_in_touch.html#no-funciona",
    "href": "get_in_touch.html#no-funciona",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "Ningún software está libre de problemas, y si encuentras un error desagradable utilizando este flujo de trabajo, utiliza la página de Issues para reportarlo.\nConsidera los siguientes pasos antes y al abrir un nuevo Issue:\n\n¿Tú o alguien más ya lo ha preguntado en GitHub Discussions? ¡La sección “Q&A” es perfecta para eso!\n¿Has comprobado que problemas similares ya hayan sido reportados? El rastreador de Issues tiene una función de filtro para buscar palabras clave en los Issues abiertos. Puedes reducir la búsqueda usando labels🏷️ como filtros. Consulta Labels para más información. Como regla general, no asignamos issues a nadie.\n\nPara abrir un nuevo Issue:\n\nHaz clic en el botón verde New issue en la esquina superior derecha y selecciona Bug report.\nDescribe tu problema con el mayor detalle posible. El issue debe indicar cuál es el problema, cuál debería ser el comportamiento esperado y, tal vez, sugerir una solución. Ten en cuenta que también puedes adjuntar archivos (por ejemplo, datos de ejemplo, código en R, etc.) o imágenes al issue.\nSelecciona una label🏷️ adecuada del menú desplegable llamado Labels.\nHaz clic en el botón verde Submit new issue y espera una respuesta."
  },
  {
    "objectID": "get_in_touch.html#podemos-añadir-esto",
    "href": "get_in_touch.html#podemos-añadir-esto",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "También usamos la página de Issues para solicitudes serias de nuevas funcionalidades. Si alguna discusión en el portal GitHub Discussions lleva a una función bien definida que te gustaría implementar, puedes enviarla como feature request:\n\nVe a la página de Issues\nHaz clic en el botón verde New issue en la esquina superior derecha y selecciona Feature request.\nDescribe la funcionalidad con el mayor detalle posible. ¿Cuál es el comportamiento esperado? ¿Qué paquetes deberíamos usar? Ten en cuenta que también puedes adjuntar archivos o imágenes al Issue.\nSelecciona una label🏷️ adecuada del menú desplegable llamado Labels.\nHaz clic en el botón verde Submit new issue y espera una respuesta."
  },
  {
    "objectID": "get_in_touch.html#actualizaciones-futuras-del-proyecto",
    "href": "get_in_touch.html#actualizaciones-futuras-del-proyecto",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "El proyecto FOSSILPOL está concebido como un software que recibirá actualizaciones para mejorar continuamente.\nSomos conscientes de las funciones y características que nos gustaría implementar en el futuro.\nConsulta las actualizaciones futuras previstas en project future updates. Las tres etapas de la solicitud son:\n\n“next version” – una función que se implementará en la próxima versión de FOSSILPOL\n“future” – una función que probablemente se implementará en una de las próximas versiones de FOSSILPOL\n“in consideration” – una función que podría implementarse, pero no es prioritaria\n\nSi hay alguna funcionalidad que te gustaría implementar, primero consulta el Issue Tracker y mira si alguien ya la ha sugerido y dale un voto positivo si ya está allí. Antes de cada lanzamiento de versión, implementaremos la funcionalidad más votada.\nNuestro objetivo es actualizar la lista regularmente."
  },
  {
    "objectID": "get_in_touch.html#contribuye",
    "href": "get_in_touch.html#contribuye",
    "title": "¡Ponte en contacto!",
    "section": "",
    "text": "El proyecto FOSSILPOL está concebido como un software que recibirá actualizaciones para mejorar continuamente.\nAgradecemos la ayuda :sparkling_heart: y gracias solo por considerar contribuir a FOSSILPOL.\nPara asegurarnos de mantener la más alta calidad de código, debemos cumplir algunas directrices estrictas. Por favor, lee este documento para ayudarte a comenzar.\nSi deseas reportar un bug, sugerir mejoras o solicitar una nueva funcionalidad, dirígete a la sección de Issues.\n\n\nUsamos el sistema de control de versiones Git para gestionar los desarrollos en el repositorio alojado en GitHub. Si eres nuevo en Git o GitHub, por favor revisa el GitHub Bootcamp para ponerte al día.\nSi ya conoces Git y GitHub, por favor revisa Submitting Pull Requests.\n\n\n\nAunque tenemos nuestro propio estilo de codificación y no seguimos ningún estándar disponible en la web, sí mantenemos cierta uniformidad.\nSi olvidamos mencionar algún caso particular, siempre debes seguir este procedimiento:\n\nMira cómo se hace en el código fuente.\nConsulta qué dice la convención de Advanced R by Hadley Wickham y elige algo que se asemeje al código base.\nSi todo lo demás falla, pregunta en GitHub Discussions\n\n\n\n\nTodos los cambios a FOSSILPOL deben ser en forma de pull request (también conocidos como PR). Si no estás familiarizado con los pull requests, por favor lee esto.\nEste es el proceso recomendado:\n\nHaz un fork del repositorio para que puedas hacer tus cambios sin afectar el proyecto original hasta que estés listo para fusionarlos. Consulta la Guía para forking\nTrabaja sobre la rama (nombrada según la próxima versión, si existe).\nHaz commit de tus actualizaciones cuando estés satisfecho con ellas. Consulta la guía de contribución para los mensajes de commit.\nCuando termines los cambios, crea un PR\n\nHaz clic en “Ready for review” para que podamos revisar tu PR. Esta plantilla ayuda a los revisores a entender tus cambios, así como el propósito de tu pull request.\nNo olvides vincular el PR al Issue si estás resolviendo uno.\nHabilita la casilla para permitir ediciones por parte de los mantenedores para que la rama pueda ser actualizada para una fusión. Una vez que envíes tu PR, un miembro del equipo HOPE revisará tu propuesta. Podemos hacer preguntas o solicitar información adicional.\nEs posible que pidamos cambios antes de poder fusionar el PR, ya sea usando cambios sugeridos o comentarios en el pull request. Puedes aplicar los cambios sugeridos directamente desde la interfaz de usuario (UI). Puedes hacer cualquier otro cambio en tu fork, y luego hacer commit a tu rama.\nA medida que actualices tu PR y apliques cambios, marca cada conversación como resuelta\nSi tienes problemas de fusión, revisa este tutorial de git para ayudarte a resolver conflictos de fusión y otros problemas.\n\n\nAntes de enviar un pull request, asegúrate de seguir todas las pautas a continuación mientras trabajas en tus cambios:\n\nCada pull request debe intentar lograr una sola tarea general.\nTodo el trabajo debe realizarse en una rama con un nombre descriptivo relacionado con la tarea general (por ejemplo, fix_bug_x o add_feature_y). Cada commit debe lograr una pequeña subtarea y debe ser explicable en una o dos frases.\nCada commit debe tener un mensaje descriptivo.\nDebes asegurarte de que tu código pase todas las pruebas antes de hacer commit."
  },
  {
    "objectID": "other_materials.html",
    "href": "other_materials.html",
    "title": "Recursos y materiales",
    "section": "",
    "text": "Aquí colocaremos material adicional (por ejemplo, presentaciones, pósteres) sobre el proyecto FOSSILPOL.\n\n\n\n“Una guía para el procesamiento y la estandarización de datos paleoecológicos globales para síntesis a gran escala utilizando polen fósil”: .\n\n\n\n\n\nCiclo de charlas Paleoverse - 2025\nPresentación IBS 2024\n\n\n\n\n\nPóster presentado en INQUA 2023 en Roma\n\n\n\n\n\nLogo FOSSILPOL PNG grande\nLogo FOSSILPOL PNG pequeño"
  },
  {
    "objectID": "other_materials.html#publicaciones",
    "href": "other_materials.html#publicaciones",
    "title": "Recursos y materiales",
    "section": "",
    "text": "“Una guía para el procesamiento y la estandarización de datos paleoecológicos globales para síntesis a gran escala utilizando polen fósil”: ."
  },
  {
    "objectID": "other_materials.html#presentaciones",
    "href": "other_materials.html#presentaciones",
    "title": "Recursos y materiales",
    "section": "",
    "text": "Ciclo de charlas Paleoverse - 2025\nPresentación IBS 2024"
  },
  {
    "objectID": "other_materials.html#pósteres",
    "href": "other_materials.html#pósteres",
    "title": "Recursos y materiales",
    "section": "",
    "text": "Póster presentado en INQUA 2023 en Roma"
  },
  {
    "objectID": "other_materials.html#logo-de-fossilpol",
    "href": "other_materials.html#logo-de-fossilpol",
    "title": "Recursos y materiales",
    "section": "",
    "text": "Logo FOSSILPOL PNG grande\nLogo FOSSILPOL PNG pequeño"
  }
]